<% \set QUIET 1 %>
<!DOCTYPE html>
<html><meta charset="utf-8" />
<style>
table, th, td { border: 1px solid black; border-collapse: collapse; padding: 2px 4px 2px 4px;}
th {background-color: #d2f2ff;cursor: pointer; }
tr:nth-child(even) {background-color: #eef8ff}
tr:hover { background-color: #FFFFCA}
h2 { scroll-margin-left: 2em;} /*keep the scroll left*/
caption { font-size: larger }
ol { width: fit-content;}
.warn { font-weight:bold; background-color: #FBA }
.high { border: 5px solid red;font-weight:bold}
.lime { font-weight:bold;background-color: #FFD}
.lineblk {float: left; margin:0 9px 4px 0 }
.bottomright { position: fixed; right: 0px; bottom: 0px; padding: 5px; border : 2px solid #AFAFFF; border-radius: 5px;}
.thidden tr td:nth-child(2), .thidden th:nth-child(2) {display: none;}
.thidden tr td:first-child {color:blue;}
#cur { font: 5em arial; position: absolute; color:brown; animation: vanish 0.8s ease forwards; }  /*sort indicator*/
#dtls,#finditem {position: absolute;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em; box-shadow: 2px 2px grey;}
@keyframes vanish { from { opacity: 1;} to {opacity: 0;} }
summary {  padding: 1rem; font: bold 1.2em arial;  cursor: pointer } 
footer { text-align: center; padding: 3px; background-color:#d2f2ff}
</style>
<% \H
\pset footer off 
SET max_parallel_workers_per_gather = 0;
%>
<h1>
  <svg width="10em" viewBox="0 0 140 80">
    <path fill="none" stroke="#000000" stroke-linecap="round" stroke-width="2"  d="m 21.2,46.7 c 1,2 0.67,4 -0.3,5.1 c -1.1,1 -2,1.5 -4,1 c -10,-3 -4,-25 -4 -25 c 0.6,-10 8,-9 8 -9 s 7,-4.5 11,0.2 c 1.2,1.4 1.7,3.3 1.7,5.17 c -0.1,3 3,7 -2,10 c-2,2 -1,5 -8,5.5 m -2 -12 c 0,0 -1,1 -0.2,0.2 m -4 12 c 0,0 0,10 -12,11"/>
    <text x="30" y="50" style="font:25px arial">gGather</text>
    <text x="60" y="62" style="fill:red; font:15px arial">Report</text>
   </svg>
   <b id="busy" class="warn"> Loading... </b>
</h1>
<% \pset tableattr 'id="tblgather" class="lineblk"'
SELECT (SELECT count(*) > 1 FROM pg_srvr WHERE connstr ilike 'You%') AS conlines \gset
\if :conlines
  \echo "There is serious problem with the data. Please make sure that all tables are dropped and recreated as part of importing data (gather_schema.sql) and there was no error"
  "SOMETHING WENT WRONG WHILE IMPORTING THE DATA. PLEASE MAKE SURE THAT ALL TABLES ARE DROPPED AND RECREATED AS PART OF IMPORTING";
  \q
\endif
\set tzone `echo "$PG_GATHER_TIMEZONE"`
SELECT * FROM 
(WITH TZ AS (SELECT CASE WHEN :'tzone' = ''
    THEN (SELECT set_config('timezone',setting,false) FROM pg_get_confs WHERE name='log_timezone')
    ELSE  set_config('timezone',:'tzone',false) 
  END AS val)
SELECT  UNNEST(ARRAY ['Collected At','Collected By','PG build', 'PG Start','In recovery?','Client','Server','Last Reload','Current LSN','Time Line','WAL file']) AS pg_gather,
        UNNEST(ARRAY [CONCAT(collect_ts::text,' (',TZ.val,')'),usr,ver, pg_start_ts::text ||' ('|| collect_ts-pg_start_ts || ')',recovery::text,client::text,server::text,reload_ts::text,
        current_wal::text,timeline::text || ' (Hex:' ||  upper(to_hex(timeline)) || ')',  lpad(upper(to_hex(timeline)),8,'0')||substring(pg_walfile_name(current_wal) from 9 for 16)]) AS "Report"
FROM pg_gather LEFT JOIN TZ ON TRUE 
UNION
SELECT  'Connection', replace(connstr,'You are connected to ','') FROM pg_srvr ) a WHERE "Report" IS NOT NULL ORDER BY 1;
\pset tableattr 'id="dbs" class="thidden"'
WITH cts AS (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather),
  wal_stat AS (SELECT stats_reset FROM pg_get_wal)
SELECT datname "DB Name",to_jsonb(ROW(tup_inserted/days,tup_updated/days,tup_deleted/days,to_char(pg_get_db.stats_reset,'YYYY-MM-DD HH24-MI-SS')))
,xact_commit/days "Avg.Commits",xact_rollback/days "Avg.Rollbacks",(tup_inserted+tup_updated+tup_deleted)/days "Avg.DMLs", CASE WHEN blks_fetch > 0 THEN blks_hit*100/blks_fetch ELSE NULL END  "Cache hit ratio"
,temp_files/days "Avg.Temp Files",temp_bytes/days "Avg.Temp Bytes",db_size "DB size",age "Age"
FROM pg_get_db LEFT JOIN wal_stat ON true
LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts-COALESCE(pg_get_db.stats_reset,wal_stat.stats_reset)))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE;
\pset tableattr off
%>
<div>
<details style="clear: left; width: fit-content;">
  <summary>Tune PostgreSQL Parameters (beta)</summary>
  <label for="cpus">CPUs:
  <input type="number" id="cpus" name="cpus" value="0">
  </label>
  <label for="mem" style="padding-left: 3em;">Memory(GB):
  <input type="number" id="mem" name="mem" value="0">
 </label>
 <p style="border: 2px solid blue; border-radius: 5px; padding: 1em;">Please input the CPU and Memory available on the host machine for evaluating the current parameter settings<br />
  Please see the tooltip against Parameters for recommendations based on calculations. Please seek expert advice</p>
</details>
</div>
<h2 id="topics">Sections</h2>
<ol>
<li><a href="#tables">Tables</a></li>
<li><a href="#indexes">Indexes</a></li>
<li><a href="#parameters">Parameters / Settings</a></li>
<li><a href="#extensions">Extensions</a></li>
<li><a href="#activiy">Connection Summary</a></li>
<li><a href="#time">Database Time</a></li>
<li><a href="#sess">Session Details</a></li>
<li><a href="#statements" title="pg_get_statements">Top 10 Statements</a></li>
<li><a href="#replstat">Replications</a></li>
<li><a href="#bgcp" >BGWriter & Checkpointer</a></li>
<li><a href="#findings">Findings</a></li>
</ol>
<div class="bottomright">
  <a href="#topics">Sections (Alt+I)</a>
</div>
<div id="sections" style="display:none">
<h2 id="tables">Tables</h2>
<p><b>NOTE : Rel size</b> is the  main fork size, <b>Tot.Tab size</b> includes all forks and toast, <b>Tab+Ind size</b> is tot_tab_size + all indexes, *Bloat estimates are indicative numbers and they can be inaccurate<br />
Objects other than tables will be marked with their relkind in brackets</p>
<% \pset footer on
\pset tableattr 'id="tabInfo" class="thidden"'%>
<% SELECT c.relname || CASE WHEN c.relkind != 'r' THEN ' ('||c.relkind||')' ELSE '' END "Name" ,
to_jsonb(ROW(r.n_tup_ins,r.n_tup_upd,r.n_tup_del,r.n_tup_hot_upd)),r.relnamespace "NS", CASE WHEN r.blks > 999 AND r.blks > tb.est_pages THEN (r.blks-tb.est_pages)*100/r.blks ELSE NULL END "Bloat%",
r.n_live_tup "Live tup",r.n_dead_tup "Dead tup", CASE WHEN r.n_live_tup <> 0 THEN  ROUND((r.n_dead_tup::real/r.n_live_tup::real)::numeric,4) END "Dead/Live",
r.rel_size "Rel size",r.tot_tab_size "Tot.Tab size",r.tab_ind_size "Tab+Ind size",r.rel_age,to_char(r.last_vac,'YYYY-MM-DD HH24:MI:SS') "Last vacuum",to_char(r.last_anlyze,'YYYY-MM-DD HH24:MI:SS') "Last analyze",r.vac_nos,
ct.relname "Toast name",rt.tab_ind_size "Toast+Ind" ,rt.rel_age "Toast Age",GREATEST(r.rel_age,rt.rel_age) "Max age"
FROM pg_get_rel r
JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')
LEFT JOIN pg_get_toast t ON r.relid = t.relid
LEFT JOIN pg_get_class ct ON t.toastid = ct.reloid
LEFT JOIN pg_get_rel rt ON rt.relid = t.toastid
LEFT JOIN pg_tab_bloat tb ON r.relid = tb.table_oid
LEFT JOIN pg_get_ns ns ON r.relnamespace = ns.nsoid
ORDER BY r.tab_ind_size DESC LIMIT 10000; %>
<% \pset tableattr%>
<h2 id="indexes">Indexes</h2>
<% \pset tableattr 'id="IndInfo"'
SELECT ct.relname AS "Table", ci.relname as "Index",indisunique as "UK?",indisprimary as "PK?",numscans as "Scans",size
  FROM pg_get_index i 
  JOIN pg_get_class ct on i.indrelid = ct.reloid and ct.relkind != 't'
  JOIN pg_get_class ci ON i.indexrelid = ci.reloid
ORDER BY size DESC LIMIT 10000;
\pset tableattr %>
<h2 id="parameters">Parameters & settings</h2>
<% \pset tableattr 'id="params"'%>
<% SELECT coalesce(s.name,f.name) "Name",s.setting,s.unit,s.source, 
string_agg(f.sourcefile ||' - '|| f.setting || CASE WHEN f.applied = true THEN ' (applicable)' ELSE '' END ,chr(10)) FILTER (WHERE s.source != f.sourcefile OR s.source IS NULL ) AS "Other locations"
FROM pg_get_confs s FULL OUTER JOIN pg_get_file_confs f ON lower(s.name) = lower(f.name)
GROUP BY 1,2,3,4 ORDER BY 1; %>
<% \pset tableattr%>
<h2 id="extensions">Extensions</h2>
<% \pset tableattr 'id="tblextn"'
SELECT ext.oid,extname,rolname as owner,extnamespace,extrelocatable,extversion FROM pg_get_extension ext
JOIN pg_get_roles on extowner=pg_get_roles.oid; %>
<h2 id="activiy">Connection Summary</h2>
<% \pset footer off
\pset tableattr 'id="tblcs"'
 SELECT d.datname,state,COUNT(pid) 
  FROM pg_get_activity a LEFT JOIN pg_get_db d on a.datid = d.datid
    WHERE state is not null GROUP BY 1,2 ORDER BY 1; %>
<h2 id="time">Database time</h2>
<% \pset tableattr 'id="tableConten" name="waits"'
\C 'Wait Events and CPU info.'
SELECT COALESCE(wait_event,'CPU') "Event", count(*)::text FROM pg_pid_wait
WHERE wait_event IS NULL OR wait_event NOT IN ('ArchiverMain','AutoVacuumMain','BgWriterHibernate','BgWriterMain','CheckpointerMain','LogicalApplyMain','LogicalLauncherMain','RecoveryWalStream','SysLoggerMain','WalReceiverMain','WalSenderMain','WalWriterMain','CheckpointWriteDelay','PgSleep','VacuumDelay')
GROUP BY 1 ORDER BY count(*) DESC;
\C
%>
<a href="https://github.com/jobinau/pg_gather/blob/main/docs/waitevents.md">Wait Event Reference</a>
<h2 id="sess" style="clear: both">Session Details</h2>
<% \pset tableattr 'id="tblsess" class="thidden"' 
SELECT * FROM (
    WITH w AS (SELECT pid, string_agg( wait_event ||':'|| cnt,',') waits, sum(cnt) pidwcnt, max(max) itr_max, min(min) itr_min FROM
    (SELECT pid,COALESCE(wait_event,'CPU') wait_event,count(*) cnt, max(itr),min(itr) FROM pg_pid_wait GROUP BY 1,2 ORDER BY cnt DESC) pw GROUP BY 1),
  g AS (SELECT MAX(state_change) as ts,MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity),
  itr AS (SELECT max(itr_max) gitr_max FROM w)
  SELECT a.pid,to_jsonb(ROW(d.datname,application_name,client_hostname,sslversion)), a.state,r.rolname "User",client_addr "client"
  , CASE query WHEN '' THEN '**'||backend_type||' process**' ELSE query END "Last statement"
  , g.ts - backend_start "Connection Since", g.ts - xact_start "Transaction Since", g.mx_xid - backend_xmin::text::bigint "xmin age",
   g.ts - query_start "Statement since",g.ts - state_change "State since", w.waits ||
   CASE WHEN (itr_max - itr_min)::float/itr.gitr_max*2000 - pidwcnt > 0 THEN
    ', Net/Delay*:' || ((itr_max - itr_min)::float/itr.gitr_max*2000 - pidwcnt)::int
   ELSE '' END waits
  FROM pg_get_activity a 
   LEFT JOIN w ON a.pid = w.pid
   LEFT JOIN itr ON true
   LEFT JOIN g ON true
   LEFT JOIN pg_get_roles r ON a.usesysid = r.oid
   LEFT JOIN pg_get_db d on a.datid = d.datid
  ORDER BY "xmin age" DESC NULLS LAST) AS sess
WHERE waits IS NOT NULL OR state != 'idle';%>
<h2 id="statements" style="clear: both">Top 10 Statements</h2>
<% \pset tableattr 'id="tblstmnt"'
\C 'Statements consuming highest database time. Consider information from pg_get_statements for other criteria'
select query,total_time,calls from pg_get_statements order by 2 desc limit 10; 
\C %>
<h2 id="replstat" style="clear: both">Replication Status</h2>
<% \pset tableattr 'id="tblreplstat"'
WITH M AS (SELECT GREATEST((SELECT(current_wal) FROM pg_gather),(SELECT MAX(sent_lsn) FROM pg_replication_stat))),
  g AS (SELECT MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity)
SELECT usename AS "Replication User",client_addr AS "Replica Address",pid,state,
 pg_wal_lsn_diff(M.greatest, sent_lsn) "Transmission Lag (Bytes)",pg_wal_lsn_diff(sent_lsn,write_lsn) "Replica Write lag(Bytes)",
 pg_wal_lsn_diff(write_lsn,flush_lsn) "Replica Flush lag(Bytes)",pg_wal_lsn_diff(flush_lsn,replay_lsn) "Replay at Replica lag(Bytes)",
 slot_name "Slot",plugin,slot_type "Type",datname "DB name",temporary,active,GREATEST(g.mx_xid-old_xmin::text::bigint,0) as "xmin age",
 GREATEST(g.mx_xid-catalog_xmin::text::bigint,0) as "catalog xmin age", GREATEST(pg_wal_lsn_diff(M.greatest,restart_lsn),0) as "Restart LSN lag(Bytes)",
 GREATEST(pg_wal_lsn_diff(M.greatest,confirmed_flush_lsn),0) as "Confirmed LSN lag(Bytes)"
FROM pg_replication_stat JOIN M ON TRUE
  FULL OUTER JOIN pg_get_slots s ON pid = active_pid
  LEFT JOIN g ON TRUE
  LEFT JOIN pg_get_db ON s.datoid = datid;
%>
<h2 id="bgcp" style="clear: both">Background Writer and Checkpointer Information</h2>
<p>Efficiency of Background writer and Checkpointer Process</p>
<% \pset tableattr 'id="tblchkpnt"'
SELECT round(checkpoints_req*100/tot_cp,1) "Forced Checkpoint %" ,
round(min_since_reset/tot_cp,2) "avg mins between CP",
round(checkpoint_write_time::numeric/(tot_cp*1000),4) "Avg CP write time (s)",
round(checkpoint_sync_time::numeric/(tot_cp*1000),4)  "Avg CP sync time (s)",
round(total_buffers::numeric*8192/(1024*1024),2) "Tot MB Written",
round((buffers_checkpoint::numeric/tot_cp)*8192/(1024*1024),4) "MB per CP",
round(buffers_checkpoint::numeric*8192/(min_since_reset*60*1024*1024),4) "Checkpoint MBps",
round(buffers_clean::numeric*8192/(min_since_reset*60*1024*1024),4) "Bgwriter MBps",
round(buffers_backend::numeric*8192/(min_since_reset*60*1024*1024),4) "Backend MBps",
round(total_buffers::numeric*8192/(min_since_reset*60*1024*1024),4) "Total MBps",
round(buffers_alloc::numeric/total_buffers,3)  "New buffers ratio",
round(100.0*buffers_checkpoint/total_buffers,1)  "Clean by checkpoints (%)",
round(100.0*buffers_clean/total_buffers,1)   "Clean by bgwriter (%)",
round(100.0*buffers_backend/total_buffers,1)  "Clean by backends (%)",
round(100.0*maxwritten_clean/(min_since_reset*60000 / delay.setting::numeric),2)   "Bgwriter halts (%) per runs (**1)",
coalesce(round(100.0*maxwritten_clean/(nullif(buffers_clean,0)/ lru.setting::numeric),2),0)  "Bgwriter halt (%) due to LRU hit (**2)",
round(min_since_reset/(60*24),1) "Reset days"
FROM pg_get_bgwriter
CROSS JOIN 
(SELECT 
    NULLIF(round(extract('epoch' from (select collect_ts from pg_gather) - stats_reset)/60)::numeric,0) min_since_reset,
    GREATEST(buffers_checkpoint + buffers_clean + buffers_backend,1) total_buffers,
    NULLIF(checkpoints_timed+checkpoints_req,0) tot_cp 
    FROM pg_get_bgwriter) AS bg
LEFT JOIN pg_get_confs delay ON delay.name = 'bgwriter_delay'
LEFT JOIN pg_get_confs lru ON lru.name = 'bgwriter_lru_maxpages'; %>
<p>**1 Percentage of bgwriter runs results in a halt, **2 Percentage of bgwriter halts are due to hitting on <code>bgwriter_lru_maxpages</code> limit</p>
<h2 id="findings" >Findings</h2>
<ol id="finditem" style="padding:2em;position:relative">
<% \pset format aligned
\pset tuples_only on
WITH W AS (SELECT COUNT(*) AS val FROM pg_get_activity WHERE state='idle in transaction')
SELECT CASE WHEN val > 0 
  THEN '<li>There are '||val||' idle in transaction session(s) </li>' 
  ELSE NULL END 
FROM W;
WITH W AS (select last_failed_time,last_archived_time,last_archived_wal from pg_archiver_stat where last_archived_time < last_failed_time)
SELECT CASE WHEN last_archived_time IS NOT NULL
  THEN '<li>WAL archiving is failing since <b>'||last_archived_time||' (duration:'|| (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather) - last_archived_time  ||') onwards</b> '  ||
  COALESCE(
  (SELECT ' With estimated size <b>' ||
  pg_size_pretty(((('x'||lpad(split_part(current_wal::TEXT,'/', 1),8,'0'))::bit(32)::bigint - ('x'||substring(last_archived_wal,9,8))::bit(32)::bigint) * 255 * 16^6 + 
  ('x'||lpad(split_part(current_wal::TEXT,'/', 2),8,'0'))::bit(32)::bigint - ('x'||substring(last_archived_wal,17,8))::bit(32)::bigint*16^6 )::bigint)
  FROM pg_gather), ' ') || '</b> behind </li>'
ELSE NULL END
FROM W;
WITH W AS (select count(*) AS val from pg_get_index i join pg_get_class ct on i.indrelid = ct.reloid and ct.relkind != 't')
SELECT CASE WHEN val > 10000
  THEN '<li>There are <b>'||val||' indexes!</b> in this database, Only biggest 10000 will be listed in this report under <a href= "#indexes" >Index Info</a>. Please use query No. 11. from the analysis_quries.sql for full details </li>'
  ELSE NULL END
FROM W;
WITH W AS (
 select string_agg(name ||'='||setting,',') as val FROM pg_get_confs WHERE 
 name in ('block_size','max_identifier_length','max_function_args','max_index_keys','segment_size','wal_block_size') AND 
 (name,setting) NOT IN (('block_size','8192'),('max_identifier_length','63'),('max_function_args','100'),('max_index_keys','32'),('segment_size','131072'),('wal_block_size','8192'))
 OR (name = 'wal_segment_size' AND unit ='8kB' and setting != '2048') OR (name = 'wal_segment_size' AND unit ='B' and setting != '16777216')  
)
SELECT CASE WHEN LENGTH(val) > 1
  THEN '<li>Detected Non-Standard Compile/Initialization time parameter changes <b>'||val||' </b>. Custom Compilation is prone to bugs, and it is beyond supportability</li>'
  ELSE NULL END
FROM W;
WITH W AS (
SELECT count(*) cnt FROM pg_get_confs WHERE source IS NOT NULL )
SELECT CASE WHEN cnt < 1
  THEN '<li>Couldn''t get parameter values. Partial gather or corrupt Parameter file(s)</li>'
  ELSE NULL END
FROM W;
SELECT 'ERROR :'||error ||': '||name||' with setting '||setting||' in '||sourcefile FROM pg_get_file_confs WHERE error IS NOT NULL;
%>
</ol>
<div id="analdata" hidden>
<% \pset format unaligned
SELECT to_jsonb(r) FROM
(SELECT 
  (select recovery from pg_gather) AS clsr,
  (SELECT to_jsonb(ROW(count(*),COUNT(*) FILTER (WHERE last_vac IS NULL),COUNT(*) FILTER (WHERE last_anlyze IS NULL))) 
     from pg_get_rel r JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')) AS tabs,
  (SELECT to_jsonb(ROW(COUNT(*),COUNT(*) FILTER (WHERE CONN < interval '15 minutes' ) )) FROM 
    (WITH g AS (SELECT MAX(state_change) as ts FROM pg_get_activity)
    SELECT pid,g.ts - backend_start CONN
    FROM pg_get_activity
    LEFT JOIN g ON true
    WHERE EXISTS (SELECT pid FROM pg_pid_wait WHERE pid=pg_get_activity.pid)
    AND backend_type='client backend') cn) AS cn,
  (select count(*) from pg_get_class where relkind='p') as ptabs,
  (SELECT  to_jsonb(ROW(count(*) FILTER (WHERE state='active' AND state IS NOT NULL), 
  count(*) FILTER (WHERE state='idle in transaction'), count(*) FILTER (WHERE state='idle'),
  count(*) FILTER (WHERE state IS NULL), count(*) FILTER (WHERE leader_pid IS NOT NULL) ,
  count(*),   count(distinct backend_type)))
  FROM pg_get_activity) as sess,
  (WITH curdb AS (SELECT trim(both '\"' from substring(connstr from '\"\w*\"')) "curdb" FROM pg_srvr WHERE connstr like '%to database%'),
    cts AS (SELECT COALESCE((SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) FROM pg_gather),current_timestamp) AS c_ts)
    SELECT to_jsonb(ROW(curdb,COALESCE(pg_get_db.stats_reset,pg_get_wal.stats_reset),c_ts,days))
    FROM  curdb LEFT JOIN pg_get_db ON pg_get_db.datname=curdb.curdb
    LEFT JOIN pg_get_wal ON true
    LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts- COALESCE(pg_get_db.stats_reset,pg_get_wal.stats_reset)))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE
    LEFT JOIN cts ON true ) as dbts,
  (SELECT json_agg(pg_get_ns) FROM  pg_get_ns WHERE nsoid > 16384 OR nsname='public') AS ns,
  (SELECT to_jsonb(ROW((collect_ts-last_archived_time) > '15 minute' :: interval, 
  pg_wal_lsn_diff(current_wal,(coalesce(nullif(ltrim(substring(last_archived_wal,9,8),'0'),''),'0') ||'/'|| substring(last_archived_wal,23,2) || '000001')::pg_lsn))) FROM pg_gather,pg_archiver_stat) AS arcfail,
  (SELECT to_jsonb(ROW(max(setting) FILTER (WHERE name = 'archive_library'), max(setting) FILTER (WHERE name = 'cluster_name'),count(*) FILTER (WHERE source = 'command line'))) FROM pg_get_confs) AS params,
  (SELECT CASE WHEN max(stats_reset)-min(stats_reset) < '2 minute' :: interval THEN min(stats_reset) ELSE NULL END 
  FROM (SELECT stats_reset FROM pg_get_db UNION SELECT stats_reset FROM pg_get_bgwriter) reset) crash,
  (WITH blockers AS (select array_agg(victim_pid) OVER () victim,blocking_pids blocker from pg_get_pidblock),
   ublokers as (SELECT unnest(blocker) AS blkr FROM blockers)
   SELECT json_agg(blkr) FROM ublokers
   WHERE NOT EXISTS (SELECT 1 FROM blockers WHERE ublokers.blkr = ANY(victim))) blkrs,
  (select json_agg((victim_pid,blocking_pids)) from pg_get_pidblock) victims,
  (select to_jsonb((EXTRACT(epoch FROM (end_ts-collect_ts)),pg_wal_lsn_diff(end_lsn,current_wal)*60*60/EXTRACT(epoch FROM (end_ts-collect_ts)))) 
  from pg_gather,pg_gather_end) sumry,
  (SELECT json_agg((relname,maint_work_mem_gb)) FROM (SELECT relname,n_live_tup*0.2*6 maint_work_mem_gb 
   FROM pg_get_rel JOIN pg_get_class ON n_live_tup > 894784853 AND pg_get_rel.relid = pg_get_class.reloid 
   ORDER BY 2 DESC LIMIT 3) AS wmemuse) wmemuse,
   (SELECT to_jsonb(ROW(count(*) FILTER (WHERE indisvalid=false),count(*) FILTER (WHERE numscans=0),count(*),sum(size) FILTER (WHERE numscans=0))) FROM pg_get_index) induse
) r;
%>
</div>
</div> <!--End of "sections"-->
<footer>End of <a href="https://github.com/jobinau/pg_gather">pgGather</a> Report</footer>
<script type="text/javascript">
//Global object to hold json values passed from the SQL analysis
obj={};
//pg_gather version
ver="22";
//Currently supported PostgreSQL versions, Extensions
meta={pgvers:["11.21","12.16","13.12","14.9","15.4"],commonExtn:["plpgsql","pg_stat_statements"],riskyExtn:["citus","tds_fdw"]};
mgrver="";
walcomprz="";
//Global variable to hold autovacuum_freeze_max_age, so that each table can be compared
autovacuum_freeze_max_age = 0;
//total DB size
totdb=0;
//Number of CPUs and Memory
totCPU=0;
totMem=0;
//Prepare the list of blockers and Victims
let blokers = []
let blkvictims = []

//When the DOM is ready
document.addEventListener("DOMContentLoaded", () => {
obj=JSON.parse( document.getElementById("analdata").innerText);
// New code for preparting victims and blockers
if (obj.victims !== null){
//each victim will have associated blockers like : victim1 : blocker1, blocker2 
//prepare the list of victims
obj.victims.forEach(function(victim){
  blkvictims.push(victim.f1);
});
//prepare the list of blockers
obj.victims.forEach(function(victim){
  //for each victim there can be multiple blockers
  victim.f2.forEach(function(blker){
    //if the blocker is not appearing in victim's list and blocker is not allready added to blockers list, add 
    if (blkvictims.indexOf(blker) == -1 && blokers.indexOf(blker) == -1) blokers.push(blker);
  });
});
}
checkgather();
checkpars();
checktabs();
checkdbs();
checkextn();
checksess();
checkfindings();
});

window.onload = function() {
// can also use window.addEventListener('load', (event) => {
  ["tabInfo","IndInfo","params","sections"].forEach(function(t) {document.getElementById(t).style="display:table";})
  document.getElementById("sections").style="display:table";
  document.getElementById("busy").style="display:none";
};

//Check the data collection of pg_gather
function checkgather(){
   const trs=document.getElementById("tblgather").rows
  for (let i = 0; i < trs.length; i++) {
    //console.log(trs[i].cells[0].innerText);
    val = trs[i].cells[1];
    switch(trs[i].cells[0].innerText){
      case "pg_gather" :
        val.innerText = val.innerText + "-v" + ver;
        break;
      case "Collected By" :
        if (val.innerText.slice(-2) < ver ) { val.classList.add("warn"); val.title = "Data collected using older version of gather.sql file" }
        break;
      case "In recovery?" :
        console.log(val.innerText);
        if(val.innerText == "true") {val.classList.add("lime"); val.title="Data collected at standby"; obj.primary = false;}
        else obj.primary = true;  //store that the instance is primary into obj
        break;
    }
  }
}

//check the obj content and display findings messages accordingly
function checkfindings(){
 let strfind = "";
 //if the number of background processes from pg_stat_activity is less than 4, then it indicates the user don't have access to pg_stat* views properly
 if (obj.sess.f7 < 4){ 
  strfind += "<li><b>The pg_gather data is collected by a user who don't have proper access / privilege</b> Please run the script as a privileged user (superuser, rds_superuser etc.) or some account with pg_monitor privilege.</li>"
  document.getElementById("tableConten").title="Waitevents data will be growsly incorrect because the pg_gather data is collected by a user who don't have proper access / privilege. Please refer the Findings section";
  document.getElementById("tableConten").caption.innerHTML += "<br/>" + document.getElementById("tableConten").title
  document.getElementById("tableConten").classList.add("high");
 }
 if (obj.cn.f1 > 0){
    strfind +="<li><b>" + obj.cn.f2 + " / " + obj.cn.f1 + " connections </b> in use are new. "
    if (obj.cn.f2 > 9 || obj.cn.f2/obj.cn.f1 > 0.7 ){
      strfind+="Please consider this for improving connection pooling"
    } 
    strfind += "</li>";
 }
 if (obj.induse.f1 > 0 ) strfind += "<li><b>"+ obj.induse.f1 +" Invalid Index(es)</b> found. Recreate or drop them. Refer <a href='https://github.com/jobinau/pg_gather/blob/main/docs/InvalidIndexes.md'>Link</a></li>";
 if (obj.induse.f2 > 0 ) strfind += "<li><b>"+ obj.induse.f2 +" out of " + obj.induse.f3 + " Index(es) are Unused, Which accounts for "+ bytesToSize(obj.induse.f4) +"</b>. Consider dropping of all unused Indexes</li>";
 if (obj.ptabs > 0) strfind += "<li><b>"+ obj.ptabs +" Natively partitioned tables</b> found. Tables section could contain partitions</li>";
 if (obj.params.f3 > 10) strfind += "<li> Patroni/HA PG cluster :<b>" + obj.params.f2 + "</b></li>"
 if(obj.clsr){
  strfind += "<li>PostgreSQL is in Standby mode or in Recovery</li>";
 }else{
  if ( obj.tabs.f2 > 0 ) strfind += "<li> <b>No vacuum info for " + obj.tabs.f2 + "</b> tables </li>";
  if ( obj.tabs.f3 > 0 ) strfind += "<li> <b>No statistics available for " + obj.tabs.f3 + " tables</b>, query planning can go wrong </li>";
  if ( obj.tabs.f1 > 10000) strfind += "<li> There are <b>" + obj.tabs.f1 + " tables</b> in the database. Only the biggest 10000 will be displayed in the report. Avoid too many tables in single database. You may use backend query (Query No.10) from analysis_queries.sql</li>";
  if (obj.arcfail != null) { //entire information can go missing if no record comes to table : pg_gather, which could happen in aurora
   if (obj.arcfail.f1 == null) strfind += "<li>No working WAL archiving and backup detected. PITR may not be possible</li>";
   if (obj.arcfail.f1) strfind += "<li>No WAL archiving happened in last 15 minutes <b>archiving could be failing</b>; please check PG logs</li>";
   //Negative values for obj.arcfail.f2 should be expected because current LSN capture happens at the beginining
   if (obj.arcfail.f2 && obj.arcfail.f2 > 0) strfind += "<li>WAL archiving is <b>lagging by "+ bytesToSize(obj.arcfail.f2,1024)  +"</b></li>";
  }
  if (obj.wmemuse !== null && obj.wmemuse.length > 0){ strfind += "<li> Biggest <code>maintenance_work_mem</code> consumers are :<b>"; obj.wmemuse.forEach(function(t,idx){ strfind += (idx+1)+". "+t.f1 + " (" + bytesToSize(t.f2) + ")    " }); strfind += "</b></li>"; }
  if (obj.victims !== null && obj.victims.length > 0) strfind += "<li>There are <b>" + obj.victims.length + " sessions blocked.</b></li>"
  if (obj.sumry !== null){ strfind += "<li>Data collection took <b>" + obj.sumry.f1 + " seconds. </b>";
     if ( obj.sumry.f1 < 23 ) strfind += "System response is good</li>";
     else if ( obj.sumry.f1 < 28 ) strfind += "System response is below average</li>";
     else strfind += "System response appears to be poor</li>";
     strfind += "<li>Current WAL generation rate is <b>" + bytesToSize(obj.sumry.f2) + " / hour</b></li>"; }
  if ( mgrver < Math.trunc(meta.pgvers[0])) strfind += "<li>PostgreSQL <b>Version : " + mgrver + " is outdated (EOL) and not supported</b>, Please upgrade urgently</li>";
  if ( mgrver >= 15 && ( walcomprz == "off" || walcomprz == "on")) strfind += "<li>The <b>wal_compression is '" + walcomprz + "' on PG"+ mgrver +"</b>, consider a good compression method (lz4,zstd)</li>"
  if (obj.ns !== null){
   let tempNScnt = obj.ns.filter(n => n.nsname.indexOf("pg_temp") > -1).length + obj.ns.filter(n => n.nsname.indexOf("pg_toast_temp") > -1).length ;
   strfind += "<li> There are <b>" + (obj.ns.length - tempNScnt).toString()  + " user schemas and " + tempNScnt + " temporary schemas</b> in this database.</li>";
  }
 }
  //update the findings section
  document.getElementById("finditem").innerHTML += strfind;

  //Add footer to database details table at the top
  var el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='9'>**Averages are Per Day. Total size of "+ (document.getElementById("dbs").tBodies[0].rows.length - 1) +" DBs : "+ bytesToSize(totdb) +"</th>";
  dbs=document.getElementById("dbs");
  dbs.appendChild(el);
  
  //Add footer to Sessions Summary table
  el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='3'>Active: "+ obj.sess.f1 +", Idle-in-transaction: " + obj.sess.f2 + ", Idle: " + obj.sess.f3 + ", Background: " + obj.sess.f4 + ", Workers: " + obj.sess.f5 + ", Total: " + obj.sess.f6 + "</th>";
  tblcs=document.getElementById("tblcs");
  tblcs.appendChild(el);

}

//Event listeners for changing the CPU and Memory
document.getElementById("cpus").addEventListener("change", (event) => {
  totCPU = event.target.value;
  checkpars();   //TODO : checking every parameter is unnessary.
});
document.getElementById("mem").addEventListener("change", (event) => {
  totMem = event.target.value;
  checkpars();   //TODO : checking every parameter is unnessary.
});


//Convert bytes into human readable formats
function bytesToSize(bytes,divisor = 1000) {
  const sizes = ["B","KB","MB","GB","TB"];
  if (bytes == 0) return "0B";
  const i = parseInt(Math.floor(Math.log(bytes) / Math.log(divisor)), 10);
  if (i === 0) return bytes + sizes[i];
  return (bytes / (divisor ** i)).toFixed(1) + sizes[i]; 
}

//Convert time format seperated by colon (:) to seconds for comparision
function DurationtoSeconds(duration){
    const [hours, minutes, seconds] = duration.split(":");
    return Number(hours) * 60 * 60 + Number(minutes) * 60 + Number(seconds);
};

//******************* New Parameter Despatch table implimentation v22 *******************/
var paramDespatch = {
  archive_mode : function(rowref){
    val=rowref.cells[1];
    if(obj.primary  == true && val.innerHTML == "off"){ val.classList.add("warn"); val.title="Primary server without WAL archiving configured. No PITR possible"}
  },
  archive_command : function(rowref) {
    val=rowref.cells[1];
    if (obj.params !== null && obj.params.f1 !== null && obj.params.f1.length > 0) { val.classList.add("warn"); val.title="archive_command won't be in-effect, because archive_library : " + obj.arclib + " is specified"  }
    else if (val.innerText.length < 5) {val.classList.add("warn"); val.title="A valid archive_command is expected for WAL archiving, unless archive library is used" ; }
  },
  autovacuum : function(rowref) {
    val=rowref.cells[1];
    if(val.innerText != "on") { val.classList.add("warn"); val.title="Autovacuum must be on" }
  },
  autovacuum_max_workers : function(rowref) {
    val=rowref.cells[1];
    if(val.innerText > 3) { val.classList.add("warn"); val.title="High number of workers causes each workers to run slower because of the cost limit" }
  },
  autovacuum_vacuum_cost_limit: function(rowref){
    val=rowref.cells[1];
    if(val.innerText > 800 || val.innerText == -1 ) { val.classList.add("warn"); val.title="Better to specify this with a value less than 800" }
  },
  autovacuum_freeze_max_age: function(rowref){
    val=rowref.cells[1];
    autovacuum_freeze_max_age = Number(val.innerText);  //Store the value to global variable
    if (autovacuum_freeze_max_age > 800000000) val.classList.add("warn");
  },
  checkpoint_timeout: function(rowref){
    val=rowref.cells[1];
    if(val.innerText < 1200) { val.classList.add("warn"); val.title="Too small gap between checkpoints"}
  },
  shared_buffers: function(rowref){
    val=rowref.cells[1];
    val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024);
    if( totMem > 0 && ( totMem < val.innerText*8*0.2/1048576 || totMem > val.innerText*8*0.3/1048576 ))
      { val.classList.add("warn"); val.title="Approx. 25% of available memory is recommended, current value of " + bytesToSize(val.innerText*8192,1024) + " appears to be off" }
  },
  max_connections: function(rowref){
    val=rowref.cells[1];
    val.title="Avoid value exceeding 10x of the CPUs"
    if( totCPU > 0 ){
      if(val.innerText > 10 * totCPU) { val.classList.add("warn"); val.title="If there is only " + totCPU + " CPUs value above " + 10*totCPU + " Is not recommendable for performance and stability" }
        else { val.classList.remove("warn"); val.classList.add("lime"); val.title="Current value is good" }
        } else if (val.innerText > 500) val.classList.add("warn")
      else val.classList.add("lime")
  },
  //Just highlight/Warn few important parameters and their values
  deadlock_timeout: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); }, 
  effective_cache_size: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024); }, 
  huge_pages: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  huge_page_size: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  hot_standby_feedback: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  jit: function(rowref){ val=rowref.cells[1]; if (val.innerText=="on") { val.classList.add("warn"); 
    val.title="Avoid JIT globally (Disable), Use only at smaller scope" }},
  maintenance_work_mem: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024,1024); },

  max_wal_size: function(rowref){
    val=rowref.cells[1];
    val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024*1024,1024);
    if(val.innerText < 10240) val.classList.add("warn");
  },
  random_page_cost: function(rowref){
    val=rowref.cells[1];
    if(val.innerText > 1.2) val.classList.add("warn");
  },
  server_version: function(rowref){
    val=rowref.cells[1];
    let setval = val.innerText.split(" ")[0]; mgrver=setval.split(".")[0];
    if ( mgrver < Math.trunc(meta.pgvers[0])){
      val.classList.add("warn"); val.title="PostgreSQL Version is outdated (EOL) and not supported";
    } else {
      meta.pgvers.forEach(function(t){
        if (Math.trunc(setval) == Math.trunc(t)){
          if (t.split(".")[1] - setval.split(".")[1] > 0 ) { val.classList.add("warn"); val.title= t.split(".")[1] - setval.split(".")[1] + " minor version updates pending. Please upgrade ASAP"; }
        }
      })  
    }
    if(val.classList.length < 1) val.classList.add("lime");  //if no problems found, just highlight the data
  },
  synchronous_standby_names: function(rowref){
    val=rowref.cells[1];
    if (val.innerText.trim().length > 0){ val.classList.add("warn"); val.title="Synchronous Standby can cause session hangs, and poor performance"; }
  },
  wal_compression: function(rowref){
    val=rowref.cells[1]; val.classList.add("lime"); walcomprz = val.innerText; //highlight and update the global variable
  },
  work_mem: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024,1024) + ", Avoid global settings above 32MB to avoid memory related issues";
    if(val.innerText > 98304) val.classList.add("warn");
    else val.classList.add("lime");
  },
  default : function(rowref) { 
      //console.log("Doing some default thing");
  }
};

// Interface function for parameter evaluation, 
// Second paramter is optional and can be called like : evalParam("autovacuum_vacuum_cost_limit"); 
var evalParam = function(param,rowref = null) {
  if (rowref.id == "") rowref.id=param;   //if rowref don't have an id, add it, This happens in the first invocation.
  else rowref = document.getElementById(param);  //No need to check like : if (rowref == null), because subsequent calls to the function is not expecting rowref
  var param = paramDespatch.hasOwnProperty(param) ? param : "default"
  paramDespatch[param](rowref);
}
//************End of Parameter Despatch table ***********************

//Check paramter values going though each in the HTML table
function checkpars(){
  trs=document.getElementById("params").rows
  for(var i=1;i<trs.length;i++) 
    evalParam(trs[i].cells[0].innerText,trs[i]);  //Despatcher function takes name of parameter and row of HTML table as parameters
 }

//Cells with value greater than autovacuum_freeze_max_age
function aged(cell){
 if(cell.innerHTML > autovacuum_freeze_max_age){ cell.classList.add("warn"); cell.title =  Number(cell.innerText).toLocaleString("en-US"); }
}

//Check Table Level info
function checktabs(){
  const startTime =new Date().getTime();
  const trs=document.getElementById("tabInfo").rows
  const len=trs.length;
  trs[0].cells[2].title="Namespace / Schema oid";trs[0].cells[3].title="Bloat in Percentage";
  [10,16,17].forEach(function(num){trs[0].cells[num].title="autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US")})
  for(var i=1;i<len;i++){
  //TODO : trs.forEach (convert the for loop to forEach if possible)
    tr=trs[i]; let TotTab=tr.cells[8]; TotTabSize=Number(TotTab.innerHTML); TabInd=tr.cells[9]; TabIndSize=(TabInd.innerHTML);
    if(TotTabSize > 5000000000 ) { TotTab.classList.add("lime"); TotTab.title = bytesToSize(TotTabSize) + "\nBig Table, Consider Partitioning, Archive+Purge"; 
    } else TotTab.title=bytesToSize(TotTabSize);
    //Tab above 20MB and with Index bigger than Tab
    if( TabIndSize > 2*TotTabSize && TotTabSize > 2000000 ){ TabInd.classList.add("warn"); TabInd.title="Indexes of : " + bytesToSize(TabIndSize-TotTabSize) + " is " + ((TabIndSize-TotTabSize)/TotTabSize).toFixed(2) + "x of Table " + bytesToSize(TotTabSize) + "\n Total : " + bytesToSize(TabIndSize)
    } else TabInd.title=bytesToSize(TabIndSize); 
    //Tab+Ind > 10GB
    if (TabIndSize > 10000000000) TabInd.classList.add("lime");
    //Check vacuum frequncy
    if (tr.cells[13].innerText / obj.dbts.f4 > 12) tr.cells[13].classList.add("warn");  tr.cells[13].title="Too frequent vacuum runs : " + Math.round(tr.cells[13].innerText / obj.dbts.f4) + "/day";
    //Check the TOAST size
    if (tr.cells[15].innerText > 10000) { 
      tr.cells[15].title=bytesToSize(Number(tr.cells[15].innerText)); 
      //if TOAST is more than 10GB
      if (tr.cells[15].innerText > 10737418240) tr.cells[15].classList.add("warn")
      else tr.cells[15].classList.add("lime")
    }
    aged(tr.cells[10]);
    aged(tr.cells[16]);
    aged(tr.cells[17]);
  }
const endTime = new Date().getTime();
console.log("time taken for checktabs :" + (endTime - startTime));
}

//Inspect database level info
function checkdbs(){
  //second column in the table is hidden, be careful
  const trs=document.getElementById("dbs").rows
  const len=trs.length;
  //array to collect dbnames where high aborts are happening
  let aborts=[];
  trs[0].cells[6].title="Average Temp generation Per Day"; trs[0].cells[7].title="Average Temp generation Per Day"; trs[0].cells[9].title="autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US");
  for(var i=1;i<len;i++){
    tr=trs[i];
    if(obj.dbts !== null && tr.cells[0].innerHTML == obj.dbts.f1) tr.cells[0].classList.add("lime");
    //High number of transaction aborts/rollbacks
    if(tr.cells[3].innerHTML > 4000){ tr.cells[3].classList.add("warn"); tr.cells[3].title = "High number of transaction aborts/rollbacks. Please inspect PostgreSQL logs"; 
     aborts.push(tr.cells[0].innerHTML)
     }
    [7,8].forEach(function(num) {  if (tr.cells[num].innerText > 1048576) { if(tr.cells[num].classList.length < 1) tr.cells[num].classList.add("lime"); tr.cells[num].title=bytesToSize(tr.cells[num].innerText) } });
    //More than 50GB temp generation per day. removing class even if it is not there is not causing any error
    if(tr.cells[7].innerHTML > 50000000000) {  tr.cells[7].classList.remove("lime"); tr.cells[7].classList.add("warn"); tr.cells[7].title += ", High temporary file generation per day. It can cause I/O performance issues" }
    totdb=totdb+Number(tr.cells[8].innerText);
    aged(tr.cells[9]);
  }
  //Mention the aborts in findings.  future append aborts array to json  : obj.aborts=aborts;
  if (aborts.length >0)
    document.getElementById("finditem").innerHTML += "<li>High number of transaction aborts/rollbacks in databases : <b>" + aborts.toString() + "</b>, please inspect PostgreSQL logs for more details</li>" ; 
}

function checkextn(){
  const trs=document.getElementById("tblextn").rows
  const len=trs.length;
  let riskyExtn=[];
  for(var i=1;i<len;i++){
    tr=trs[i];
    //if the extension name is found in riskyExtn list, warn
    if (meta.riskyExtn.includes(tr.cells[1].innerHTML)){ tr.cells[1].classList.add("warn"); tr.cells[1].title = "Risky to use in mission critical systems without support aggrement. Crashes are reported" ; }
    //else if the extension name is not found in meta.commonExtn, highlight it.
    else if (!meta.commonExtn.includes(tr.cells[1].innerHTML)) tr.cells[1].classList.add("lime");
  }
}

//Sort logic
const getCellValue = (tr, idx) => tr.children[idx].innerText || tr.children[idx].textContent;
const comparer = (idx, asc) => (a, b) => ((v1, v2) =>   v1 !== ''' && v2 !== ''' && !isNaN(v1) && !isNaN(v2) ? v1 - v2 : v1.toString().localeCompare(v2))(getCellValue(asc ? a : b, idx), getCellValue(asc ? b : a, idx));
document.querySelectorAll(''th'').forEach(th => th.addEventListener(''click'', (() => {
  const table = th.closest(''table'');
  th.style.cursor = "progress";
  var el=document.createElement("div");
  el.setAttribute("id", "cur");
  if (this.asc) el.textContent = "⬆";
  else el.textContent = "⬇";
  th.appendChild(el);
  setTimeout(() => { el.remove();},1000);
  setTimeout(function (){
  Array.from(table.querySelectorAll(''tr:nth-child(n+2)'')).sort(comparer(Array.from(th.parentNode.children).indexOf(th), this.asc = !this.asc)).forEach(tr => table.appendChild(tr) );
  setTimeout(function(){th.style.cursor = "pointer";},10);
  },50);
})));

/////############## Pop-up details box######################
//Pop-up at DB info
function dbsdtls(th){
  let o=JSON.parse(th.cells[1].innerText);
  let str="";
  if(th.cells[0].classList.contains("lime")) str = "<br/>(pg_gather connected)";
  return "<b>" + th.cells[0].innerText + "</b>" + str + "<br/> Inserts per day : " + o.f1 + "<br/>Updates per day : " + o.f2 + "<br/>Deletes per day : " + o.f3 + "<br/>Stats Reset : " + o.f4 ;
}

//Pop-up for Tables.
function tabdtls(th){
  let o=JSON.parse(th.cells[1].innerText);
  let vac=th.cells[13].innerText;
//lookup cells[2] value, the oid of NS in the obj.ns json collection  
  let ns=obj.ns.find(el => el.nsoid === JSON.parse(th.cells[2].innerText).toString());
  let str=""
  if (obj.dbts.f4 < 1) obj.dbts.f4 = 1;
  if (vac > 0) str="<br />Vacuums / day : " + Number(vac/obj.dbts.f4).toFixed(1);
  str += "<br/>Inserts / day : " + Math.round(o.f1/obj.dbts.f4);
  str += "<br/>Updates / day : " + Math.round(o.f2/obj.dbts.f4);
  str += "<br/>Deletes / day : " + Math.round(o.f3/obj.dbts.f4);
  str += "<br/>HOT.updates / day : " + Math.round(o.f4/obj.dbts.f4);
  if (o.f2 > 0) str += "<br/>FILLFACTOR recommendation :" + Math.round(100 - 20*o.f2/(o.f2+o.f1)+ 20*o.f2*o.f4/((o.f2+o.f1)*o.f2));
  if (vac/obj.dbts.f4 > 50) { 
    let threshold = Math.round((Math.round(o.f2/obj.dbts.f4) + Math.round(o.f3/obj.dbts.f4))/48);
    if (threshold < 500) threshold = 500;
    str += "<br/>AUTOVACUUM recommendation : autovacuum_vacuum_threshold = "+ threshold +", autovacuum_analyze_threshold = " + threshold
  }
  return "<b>" + th.cells[0].innerText + "</b><br/>Schema : " + ns.nsname + str;
}

//Pop-up for Session details
function sessdtls(th){
  let o=JSON.parse(th.cells[1].innerText); let str="";
  if (o.f1 !== null) str += "Database :" + o.f1 + "<br/>";
  if (o.f2 !== null && o.f2.length > 1 ) str += "Application :" + o.f2 + "<br/>";
  if (o.f3 !== null) str += "Client Host :" + o.f3 + "<br/>";
  if (typeof o.f5 != "undefined") str += ''<div class="warn">Victim of Blocker :'' + o.f5 + "<div>";
  if (str.length < 1) str+="Independent/Background process";
  return str;
}

//Every HTML Table with hidden columns
document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseover", (() => {
  th=td.parentNode;
  tab=th.closest("table");
  var el=document.createElement("div");
  el.setAttribute("id", "dtls");
  el.setAttribute("align","left");
  if(tab.id=="dbs") el.innerHTML=dbsdtls(th);
  if(tab.id=="tabInfo") el.innerHTML=tabdtls(th);
  if(tab.id=="tblsess") el.innerHTML=sessdtls(th);
  th.cells[2].appendChild(el);
})));

//On mouseout, remove the div element. "fistchild" don't have the div element
document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseout", (() => {
  td.parentNode.cells[2].innerHTML=td.parentNode.cells[2].firstChild.textContent;
})));
//################End of popup box##########################

//################ SQL query string handling #####################
document.querySelectorAll("#tblsess tr td:nth-child(6)").forEach(td => td.addEventListener("dblclick", (() => {
  if (td.title){
  console.log(td.title);
  navigator.clipboard.writeText(td.title).then(() => {  
    var el=document.createElement("div");
    el.setAttribute("id", "cur");
    el.textContent = "SQL text is copied to clipboard";
    td.appendChild(el);
    setTimeout(() => { el.remove();},2000);
   });
}
})));
//################ End of Expand box for query string ###############

//Index analysis
trs=document.getElementById("IndInfo").rows;
for (let tr of trs) {
  if(tr.cells[4].innerText == 0) {tr.cells[4].classList.add("warn"); tr.cells[4].title="Unused Index"}
  tr.cells[5].title=bytesToSize(Number(tr.cells[5].innerText));
  if(tr.cells[5].innerText > 2000000000) tr.cells[5].classList.add("lime");
}

//database time draw graph
trs=document.getElementById("tableConten").rows;
if (trs.length > 1){ 
  maxevnt=Number(trs[1].cells[1].innerText);
  for (let tr of trs) {
  evnts=tr.cells[1];
  if (evnts.innerText*1500/maxevnt > 1) evnts.innerHTML += ''<div style="display:inline-block;width:'+ Number(evnts.innerText)*1500/maxevnt + 'px; border: 7px outset brown; border-width:7px 0; margin:0 5px;box-shadow: 2px 2px grey;">''
  }
}else {
  document.getElementById("tableConten").remove();
  document.getElementById("time").innerText="Database wait events are not found"  
}


//Session information.
function checksess(){
trs=document.getElementById("tblsess").rows;
for (let tr of trs){
 //column references
 pid=tr.cells[0]; sql=tr.cells[5]; xidage=tr.cells[8]; stime=tr.cells[10];
 if(xidage.innerText > 20) xidage.classList.add("warn");
 //if pid exists in blockers list and victims list
 if (blokers.indexOf(Number(pid.innerText)) > -1){ pid.classList.add("high"); pid.title="Blocker"; };
 if (blkvictims.indexOf(Number(pid.innerText)) > -1) { pid.classList.add("warn"); 
        //pid.title="Victim of blocker : " + obj.victims.find(el => el.f1 == pid.innerText).f2.toString(); 
        tr.cells[1].innerText = tr.cells[1].innerText.slice(0,-1) + '',"f5":"' + obj.victims.find(el => el.f1 == pid.innerText).f2.toString() + '"}'';
      };
 if(DurationtoSeconds(stime.innerText) > 300) stime.classList.add("warn");
 //if query text is more than 100 chars, copy that to title and trim the query string to 100
 if (sql.innerText.length > 10 && !sql.innerText.startsWith("**") ){ sql.title = sql.innerText; 
 sql.innerText = sql.innerText.substring(0, 100); 
}
}} //editor may show extra } :)

//if there is no info from pg_stat_statements
if(document.getElementById("tblstmnt").rows.length < 2){ 
  document.getElementById("tblstmnt").remove();
  document.getElementById("statements").innerText="pg_stat_statements info is not available"
}

//Checkpointer and bgwriter info
trs=document.getElementById("tblchkpnt").rows;
if (trs.length > 1){
  tr=trs[1]
  if (tr.cells[0].innerText > 10){
    tr.cells[0].classList.add("high"); tr.cells[0].title="More than 10% of forced checkpoints is not desirable, increase max_wal_size";
  }
  if(tr.cells[1].innerText < 10 ){
    tr.cells[1].classList.add("high"); tr.cells[1].title="checkpoints are too frequent. consider checkpoint_timeout=1800";
  }
  if(tr.cells[13].innerText > 25){
    tr.cells[13].classList.add("high"); tr.cells[13].title="too many dirty pages cleaned by backends";
    if(tr.cells[12].innerText < 30){
      tr.cells[12].classList.add("high"); tr.cells[12].title="bgwriter is not efficient";
      if(tr.cells[14].innerText < 30){
        tr.cells[14].classList.add("high"); tr.cells[14].title="bgwriter could run more frequently. reduce bgwriter_delay";
      }
      if(tr.cells[15].innerText > 30){
        tr.cells[15].classList.add("high"); tr.cells[15].title="bgwriter halts too frequently. increase bgwriter_lru_maxpages";
      }
    }
  }
  //if "Reset days" is empty
  if (tr.cells[16].innerText.trim() == "" || tr.cells[16].innerText < 1 ){
    tr.cells[16].classList.add("high"); tr.cells[16].title="sufficient bgwriter stats are not available";
    document.getElementById("tblchkpnt").classList.add("high");
    document.getElementById("tblchkpnt").title = "Sufficient bgwriter stats are not available. This could happen if data is collected immediately after the stats reset or a crash. At least one day of stats are required to do meaningful calculations";
  }
}

//Check Replication status
tab=document.getElementById("tblreplstat")
if (tab.rows.length > 1){
  for(var i=1;i<tab.rows.length;i++){
    row=tab.rows[i];
    [4,5,6,7,16,17].forEach(function(num){ cell=row.cells[num]; cell.title=bytesToSize(Number(cell.innerText),1024); 
     if(cell.innerText > 104857600){
      cell.classList.add("warn");
     }else{
      cell.classList.add("lime");
     }
    });
    //xmin age check
    [14,15].forEach(function(num){  if(row.cells[num].innerText > 20) row.cells[num].classList.add("warn"); });
    //check for abandoned replication slots
    if (row.cells[13].innerText == "f" || row.cells[2].innerText == "") {
      row.cells[8].classList.add("high");
      row.cells[8].title="Abandoned replication slot";
      document.getElementById("finditem").innerHTML += "<li> Abandoned replication slot : <b>" +  row.cells[8].innerText + "</b> found. This can cause unwanted WAL retention" ;
    }
  }
}else{
  tab.remove()
  h2=document.getElementById("replstat")
  h2.innerText="No Replication found"
}


//Press Alt_i to go to topics
document.onkeyup = function(e) {
  if (e.altKey && e.which === 73) document.getElementById("topics").scrollIntoView({behavior: "smooth"});
  //       e.preventDefault();
}
</script>
</html>
