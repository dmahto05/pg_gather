<% \set QUIET 1 %>
<!DOCTYPE html>
<html><meta charset="utf-8" />
<style>
#finditem,#paramtune,table {box-shadow: 0px 20px 30px -10px grey; margin: 2em; caption {font:large bold; text-align:left; span {font: italic bold 1.7em Georgia, serif}}}
table, th, td { border: 1px solid black; border-collapse: collapse; padding: 2px 4px 2px 4px;} 
th {background-color: #d2f2ff;cursor: pointer; }
tr:nth-child(even) {background-color: #eef8ff} 
a:hover,tr:hover { background-color: #EBFFDA}
/* h2 { scroll-margin-left: 2em;} keep the scroll left
caption { font-size: larger } */
ol { width: fit-content;}
.warn { font-weight:bold; background-color: #FBA }
.high { border: 5px solid red;font-weight:bold}
.lime { font-weight:bold;background-color: #FFD}
.lineblk {float: left; margin:2em }
.thidden tr { td:nth-child(2),th:nth-child(2) {display: none} td:first-child {color:blue}}
#bottommenu { position: fixed; right: 0px; bottom: 0px; padding: 5px; border : 2px solid #AFAFFF; border-radius: 5px; z-index: 100;}
#cur { font: 5em arial; position: absolute; color:brown; animation: vanish 2s ease forwards; }  /*sort indicator*/
#dtls,#finditem,#paramtune,#menu { font-weight:initial;line-height:1.5em;position:absolute;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em;box-shadow: 0px 20px 30px -10px grey}
@keyframes vanish { from { opacity: 1;} to {opacity: 0;} }
summary {  padding: 1rem; font: bold 1.2em arial;  cursor: pointer } 
footer { text-align: center; padding: 3px; background-color:#d2f2ff}
</style>
<% \H
\pset footer off 
SET max_parallel_workers_per_gather = 0;
-- SELECT setting AS pgver FROM pg_get_confs WHERE name = 'server_version_num' \gset
%>
<h1>
  <svg width="10em" viewBox="0 0 140 80">
    <path fill="none" stroke="#000000" stroke-linecap="round" stroke-width="2"  d="m 21.2,46.7 c 1,2 0.67,4 -0.3,5.1 c -1.1,1 -2,1.5 -4,1 c -10,-3 -4,-25 -4 -25 c 0.6,-10 8,-9 8 -9 s 7,-4.5 11,0.2 c 1.2,1.4 1.7,3.3 1.7,5.17 c -0.1,3 3,7 -2,10 c-2,2 -1,5 -8,5.5 m -2 -12 c 0,0 -1,1 -0.2,0.2 m -4 12 c 0,0 0,10 -12,11"/>
    <text x="30" y="50" style="font:25px arial">gGather</text>
    <text x="60" y="62" style="fill:red; font:15px arial">Report</text>
   </svg>
   <b id="busy" class="warn"> Loading... </b>
</h1>
<% \pset tableattr 'id="tblgather" class="lineblk"'
SELECT (SELECT count(*) > 1 FROM pg_srvr WHERE connstr ilike 'You%') AS conlines \gset
\if :conlines
  \echo "There is serious problem with the data. Please make sure that all tables are dropped and recreated as part of importing data (gather_schema.sql) and there was no error"
  "SOMETHING WENT WRONG WHILE IMPORTING THE DATA. PLEASE MAKE SURE THAT ALL TABLES ARE DROPPED AND RECREATED AS PART OF IMPORTING";
  \q
\endif
\set tzone `echo "$PG_GATHER_TIMEZONE"`
SELECT * FROM 
(WITH TZ AS (SELECT CASE WHEN :'tzone' = ''
    THEN (SELECT set_config('timezone',setting,false) FROM pg_get_confs WHERE name='log_timezone')
    ELSE  set_config('timezone',:'tzone',false) 
  END AS val)
SELECT  UNNEST(ARRAY ['Collected At','Collected By','PG build', 'Last Startup','In recovery?','Client','Server','Last Reload','Latest xid','Oldest xid ref','Current LSN','Time Line','WAL file','System']) AS pg_gather,
        UNNEST(ARRAY [CONCAT(collect_ts::text,' (',TZ.val,')'),usr,ver, pg_start_ts::text ||' ('|| collect_ts-pg_start_ts || ')',recovery::text,client::text,server::text,reload_ts::text || ' ('|| collect_ts-reload_ts || ')',
        pg_snapshot_xmax(snapshot)::text,pg_snapshot_xmin(snapshot)::text,current_wal::text,timeline::text || ' (Hex:' ||  upper(to_hex(timeline)) || ')',  lpad(upper(to_hex(timeline)),8,'0')||substring(pg_walfile_name(current_wal) from 9 for 16),
        'ID: ' || systemid || ' Since: ' || to_timestamp ( systemid >> 32 ) || ' ('|| collect_ts-to_timestamp ( systemid >> 32 ) || ')']) AS "Report"
FROM pg_gather LEFT JOIN TZ ON TRUE 
UNION
SELECT  'Connection', replace(connstr,'You are connected to ','') FROM pg_srvr ) a WHERE "Report" IS NOT NULL ORDER BY 1;
\pset tableattr 'id="dbs" class="thidden"'
\C ''
WITH cts AS (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather),
  wal_stat AS (SELECT stats_reset FROM pg_get_wal)
SELECT datname "DB Name",to_jsonb(ROW(tup_inserted/days,tup_updated/days,tup_deleted/days,to_char(pg_get_db.stats_reset,'YYYY-MM-DD HH24-MI-SS'),datid,mxidage))
,xact_commit/days "Avg.Commits",xact_rollback/days "Avg.Rollbacks",(tup_inserted+tup_updated+tup_deleted)/days "Avg.DMLs", CASE WHEN blks_fetch > 0 THEN blks_hit*100/blks_fetch ELSE NULL END  "Cache hit ratio"
,temp_files/days "Avg.Temp Files",temp_bytes/days "Avg.Temp Bytes",db_size "DB size",age "Age"
FROM pg_get_db LEFT JOIN wal_stat ON true
LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts-COALESCE(pg_get_db.stats_reset,wal_stat.stats_reset)))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE;
\pset tableattr off
%>
<div>
<details style="clear: left; border: 2px solid #b3aeae; border-radius: 5px; padding: 1em;margin: 2em;">
  <summary style="font: italic bold 2em Georgia">Parameter Recommendations</summary>
  <fieldset style="border: 2px solid blue; border-radius: 5px; padding: 1em; width: fit-content;">
  <legend>Inputs</legend>
  <label for="cpus">CPUs:
  <input type="number" id="cpus" name="cpus" value="0">
  </label>
  <label for="mem" style="padding-left: 3em;">Memory(GB):
  <input type="number" id="mem" name="mem" value="0">
 </label>
 <label for="strg" style="padding-left: 3em;"> Storage:
  <select id="strg" name="strg">
    <option value="ssd">SSD/NVMe</option>
    <option value="san">SAN</option>
    <option value="mag">Magnetic</option>
   </select>
 </label>
 <label for="wrkld" style="padding-left: 3em;"> Work load:
  <select id="wrkld" name="wrkld">
    <option value="oltp">OLTP</option>
    <option value="olap">OLAP</option>
    <option value="mixed">Mixed</option>
   </select>
 </label>
 <label for="flsys" style="padding-left: 3em;"> Filesystem:
  <select id="flsys" name="flsys">
    <option value="rglr">Regular (like: ext4/xfs)</option>
    <option value="cow">COW (like: zfs/btrfs)</option>
   </select>
 </label>
 <p>☛ Please provide the CPU and memory available on the host machine. Choose the most suitable options from the list to receive specific recommendations. If you're unsure, seek expert guidance.</p>
</fieldset>
  <div id="paramtune" style="padding:2em;position:relative;width: fit-content;">
   <h3 style="font: italic 1.2em Georgia, serif;text-decoration: underline; margin: 0 0 0.5em;">Recommendations:</h3>
  <ol>
  </ol>
  <p>* Collecting pg_gather data during right utilization levels is important to tune the system for the specific workload</p>
</div>
  <button type="button" onclick="getreccomendation()" title="Calculate / Recalculate Parameters">&#128257; Calculate</button>
  <button type="button" onclick="copyashtml()" title="Copy as html tags">Copy as HTML tags</button>
  <button type="button" onclick="copyrichhtml()" title="Copy as Rich HTML">Copy as Rich HTML</button>
</details>
</div>
<h2 id="topics">Sections</h2>
<ol>
<li><a href="#tabInfo">Tables</a></li>
<li><a href="#tabPart">Partition info</a></li>
<li><a href="#IndInfo">Indexes</a></li>
<li><a href="#params">Parameters / Settings</a></li>
<li><a href="#tblextn">Extensions</a></li>
<li><a href="#tblhba">Security-HBA rules</a>
<li><a href="#tblcs">Connection & Users</a></li>
<li><a href="#tableConten">Database Time</a></li>
<li><a href="#tblsess">Session Details</a></li>
<li><a href="#tblstmnt">Top Statements</a></li>
<li><a href="#tblreplstat">Replications</a></li>
<li><a href="#tblchkpnt" >BGWriter & Checkpointer</a></li>
<li><a href="#finditem">Findings</a></li>
</ol>
<div id="bottommenu">
 <a href="#topics" title="Sections">☰ Section Index (Alt+I)</a>
 <div id="menu" style="display:none; position: relative">
  <ol>
    <li><a href="#tblgather">Head Info</a></li>
    <li><a href="#tabInfo">Tables</a></li>
    <li><a href="#tabPart">Partition info</a></li>
    <li><a href="#IndInfo">Indexes</a></li>
    <li><a href="#params">Parameters / Settings</a></li>
    <li><a href="#tblextn">Extensions</a></li>
    <li><a href="#tblhba">Security-HBA rules</a>
    <li><a href="#tblcs">Connection & Users</a></li>
    <li><a href="#tableConten">Database Time</a></li>
    <li><a href="#tblsess">Session Details</a></li>
    <li><a href="#tblstmnt">Top Statements</a></li>
    <li><a href="#tblreplstat">Replications</a></li>
    <li><a href="#tblchkpnt" >BGWriter & Checkpointer</a></li>
    <li><a href="#tbliostat">IO Statistics</a></li>
    <li><a href="#finditem">Findings</a></li>
  </ol>
 </div>
</div>
<div id="sections" style="display:none">
<% \pset footer on
\pset tableattr 'id="tabInfo" class="thidden"'
SELECT c.relname || CASE WHEN inh.inhrelid IS NOT NULL THEN ' (part)' WHEN c.relkind != 'r' THEN ' ('||c.relkind||')' ELSE '' END "Name" ,
to_jsonb(ROW(r.relid,r.n_tup_ins,r.n_tup_upd,r.n_tup_del,r.n_tup_hot_upd,isum.totind,isum.ind0scan,isum.pk,isum.uk,inhp.relname,inhp.relkind,c.relfilenode,c.reltablespace,c.reloptions)),r.relnamespace "NS", CASE WHEN r.blks > 999 AND r.blks > tb.est_pages THEN (r.blks-tb.est_pages)*100/r.blks ELSE NULL END "Bloat%",
r.n_live_tup "Live",r.n_dead_tup "Dead", CASE WHEN r.n_live_tup <> 0 THEN  ROUND((r.n_dead_tup::real/r.n_live_tup::real)::numeric,1) END "D/L",
r.rel_size "Rel size",r.tot_tab_size "Tot.Tab size",r.tab_ind_size "Tab+Ind size",r.rel_age,to_char(r.last_vac,'YYYY-MM-DD HH24:MI:SS') "Last vacuum",to_char(r.last_anlyze,'YYYY-MM-DD HH24:MI:SS') "Last analyze",r.vac_nos "Vaccs",
ct.relname "Toast name",rt.tab_ind_size "Toast + Ind" ,rt.rel_age "Toast Age",GREATEST(r.rel_age,rt.rel_age) "Max age",
c.blocks_fetched "Fetch",c.blocks_hit*100/nullif(c.blocks_fetched,0) "C.Hit%",to_char(r.lastuse,'YYYY-MM-DD HH24:MI:SS') "Last Use"
FROM pg_get_rel r
JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')
LEFT JOIN pg_get_toast t ON r.relid = t.relid
LEFT JOIN pg_get_class ct ON t.toastid = ct.reloid
LEFT JOIN pg_get_rel rt ON rt.relid = t.toastid
LEFT JOIN pg_tab_bloat tb ON r.relid = tb.table_oid
LEFT JOIN pg_get_inherits inh ON r.relid = inh.inhrelid
LEFT JOIN pg_get_class inhp ON inh.inhparent = inhp.reloid
LEFT JOIN (SELECT count(indexrelid) totind,count(indexrelid)FILTER( WHERE numscans=0 ) ind0scan, count(indexrelid) FILTER (WHERE indisprimary) pk,  
   count(indexrelid) FILTER (WHERE indisunique) uk, indrelid FROM pg_get_index GROUP BY indrelid ) AS isum ON isum.indrelid = r.relid
ORDER BY r.tab_ind_size DESC LIMIT 10000;

\pset tableattr 'id="tabPart"'
SELECT p.relname "Partitioned Table", CASE p.relkind WHEN 'p' THEN 'Native' WHEN 'r' THEN 'Inheritance' ELSE p.relkind END "Partitioning Type",
count(c.reloid) "Partitions", sum(r.tot_tab_size) "Tot.Tab size", sum(r.tab_ind_size) "Tab+Ind size"
FROM pg_get_class c JOIN pg_get_inherits i ON c.reloid = i.inhrelid
JOIN pg_get_class p ON i.inhparent = p.reloid
LEFT JOIN pg_get_rel r ON c.reloid = r.relid 
WHERE p.relkind != 'I'
GROUP BY 1,2;

\pset tableattr 'id="IndInfo"'
SELECT ct.relname AS "Table", ci.relname as "Index",indisunique as "UK?",indisprimary as "PK?",numscans as "Scans",size,ci.blocks_fetched "Fetch",ci.blocks_hit*100/nullif(ci.blocks_fetched,0) "C.Hit%", to_char(i.lastuse,'YYYY-MM-DD HH24:MI:SS') "Last Use"
  FROM pg_get_index i 
  JOIN pg_get_class ct on i.indrelid = ct.reloid and ct.relkind != 't'
  JOIN pg_get_class ci ON i.indexrelid = ci.reloid
ORDER BY size DESC LIMIT 10000;

\pset tableattr 'id="params"'
WITH dset AS (
SELECT string_agg(setting,chr(10)) setting,a.name FROM
(SELECT btrim(CASE WHEN rolname IS NULL THEN '' ELSE 'User: '|| rolname ||' , ' END || CASE WHEN datname IS NULL THEN '' ELSE 'DB: '|| datname END ,' ,') || ' ==> ' ||setting AS setting
,split_part(setting,'=',1) AS name
FROM pg_get_db_role_confs drc
LEFT JOIN LATERAL unnest(config) AS setting ON TRUE
LEFT JOIN pg_get_db db ON drc.db = db.datid
LEFT JOIN pg_get_roles rol ON rol.oid = drc.setrole
ORDER BY 1,2 NULLS LAST
) AS a GROUP BY 2 ),
fset AS (SELECT coalesce(s.name,f.name) AS name
,s.setting,s.unit,s.source
,string_agg(f.sourcefile ||' - '|| f.setting || CASE WHEN f.applied = true THEN ' (applicable)' ELSE '' END ,chr(10)) FILTER (WHERE s.source != f.sourcefile OR s.source IS NULL ) AS loc
FROM pg_get_confs s FULL OUTER JOIN pg_get_file_confs f ON lower(s.name) = lower(f.name)
GROUP BY 1,2,3,4 ORDER BY 1)
SELECT fset.name "Name",fset.setting "Setting",fset.unit "Unit",fset.source "Current Source",
CASE WHEN dset.setting IS NULL THEN '' ELSE dset.setting ||chr(10) END || CASE WHEN fset.loc IS NULL THEN '' ELSE fset.loc END AS "Other Locations & Values"
FROM fset LEFT JOIN dset ON fset.name = dset.name;

\pset footer off
\pset tableattr 'id="tblextn"'
SELECT ext.oid,extname "Extension",rolname "Owner",nsname "Schema", extrelocatable "Relocatable?",extversion "Version" 
FROM pg_get_extension ext LEFT JOIN pg_get_roles ON extowner=pg_get_roles.oid
LEFT JOIN pg_get_ns ON extnamespace = nsoid;

\pset tableattr 'id="tblhba"'
WITH rules AS (SELECT * FROM pg_get_hba_rules WHERE mask IS NOT NULL AND addr NOT IN ('all','samehost','samenet')),
cidr AS (SELECT seq, COALESCE(sum((length(mask) - length(replace(mask, ip4mask.col1, ''))) / length(ip4mask.col1) * ip4mask.col2) ,
 sum((length(mask) - length(replace(mask, ip6mask.col1, ''))) / length(ip6mask.col1) * ip6mask.col2)) "CIDR Mask"
FROM rules
LEFT JOIN (VALUES ('255',8),('254',7),('252',6),('248',5),('240',4),('224',3),('192',2),('128',1)) AS ip4mask (col1,col2)
  ON family(addr::inet) = 4
LEFT JOIN (VALUES ('8',1),('c',2),('e',3),('f',4)) AS ip6mask (col1,col2) ON family(addr::inet) = 6
GROUP BY 1)
SELECT hba.seq "Line",typ "Type",db "DB",usr "USER",addr "Address", "CIDR Mask", mask "DDN/Binary Mask",
CASE WHEN addr IN ('all','samehost','samenet') OR ( mask IS NULL AND addr IS NOT NULL) THEN 'IPv4,IPv6'
 ELSE 'IPv'||family(addr::inet)
END  "IP" ,method "Method", err
FROM  pg_get_hba_rules hba  LEFT JOIN cidr ON cidr.seq = hba.seq;

\pset tableattr 'id="tblcs" class="lineblk thidden"'
WITH db_role AS (SELECT 
pg_get_activity.datid,rolname,count(*) FILTER (WHERE state='active') as active,
count(*) FILTER (WHERE state='idle in transaction') as idle_in_transaction,
count(*) FILTER (WHERE state='idle') as idle,
count(*) as totalcons,
count (*) FILTER (WHERE ssl = true) as sslcons,
count (*) FILTER (WHERE ssl = false) as nonsslcons
FROM pg_get_activity 
  LEFT JOIN pg_get_roles on usesysid=pg_get_roles.oid
  LEFT JOIN pg_get_db on pg_get_activity.datid = pg_get_db.datid
GROUP BY 1,2
ORDER BY 1,2),
db AS (SELECT datid,sum(active) "Active",sum(idle_in_transaction) "IdleInTrans",sum(idle) "Idle",sum(totalcons) "Total",sum(sslcons) "SSL",sum(nonsslcons) "NonSSL"
FROM db_role GROUP BY 1)
SELECT pg_get_db.datname "Database",
(SELECT json_agg(ROW(rolname,active,idle_in_transaction,idle,totalcons,sslcons,nonsslcons)) FROM db_role WHERE db_role.datid = pg_get_db.datid),
"Active","IdleInTrans","Idle","Total","SSL","NonSSL"
FROM pg_get_db LEFT JOIN db ON pg_get_db.datid = db.datid;

\pset tableattr 'id="tblusr" class="thidden"'
WITH rol_db AS (SELECT 
rolname,datname,count(*) FILTER (WHERE state='active') as active,
count(*) FILTER (WHERE state='idle in transaction') as idle_in_transaction,
count(*) FILTER (WHERE state='idle') as idle,
count(*) as totalcons,
count (*) FILTER (WHERE ssl = true) as sslcons,
count (*) FILTER (WHERE ssl = false) as nonsslcons
FROM pg_get_activity 
  join pg_get_roles on usesysid=pg_get_roles.oid
  join pg_get_db on pg_get_activity.datid = pg_get_db.datid
GROUP BY 1,2
ORDER BY 1,2),
rol AS (SELECT rolname,sum(active) "Active",sum(idle_in_transaction) "IdleInTrans",sum(idle) "Idle",sum(totalcons) "Total",sum(sslcons) "SSL",sum(nonsslcons) "NonSSL"
FROM rol_db GROUP BY 1)
SELECT pg_get_roles.rolname "User",
(SELECT json_agg(ROW(datname,active,idle_in_transaction,idle,totalcons,sslcons,nonsslcons)) FROM rol_db WHERE rol_db.rolname = pg_get_roles.rolname),
rolsuper "Super?",rolreplication "Repl?", CASE WHEN rolconnlimit > -1 THEN rolconnlimit ELSE NULL END  "Limit", 
CASE enc_method WHEN 'm' THEN 'MD5' WHEN 'S' THEN 'SCRAM' END "Enc",
"Active","IdleInTrans","Idle","Total","SSL","NonSSL"
FROM pg_get_roles LEFT JOIN rol ON pg_get_roles.rolname = rol.rolname;

\pset tableattr 'id="tableConten" name="waits" style="clear: left"'
\C 'WaitEvents'
SELECT COALESCE(wait_event,'CPU') "Event", count(*)::text FROM pg_pid_wait
WHERE wait_event IS NULL OR wait_event NOT IN ('ArchiverMain','AutoVacuumMain','BgWriterHibernate','BgWriterMain','CheckpointerMain','LogicalApplyMain','LogicalLauncherMain','RecoveryWalStream','SysLoggerMain','WalReceiverMain','WalSenderMain','WalWriterMain','CheckpointWriteDelay','PgSleep','VacuumDelay')
GROUP BY 1 ORDER BY count(*) DESC;

\pset tableattr 'id="tblsess" class="thidden"' 
\C 'Sessions'
SELECT * FROM (
    WITH w AS (SELECT pid, string_agg( wait_event ||': '|| cnt*100::float/2000 ||'%',', ') waits, sum(cnt) pidwcnt, max(max) itr_max, min(min) itr_min FROM
    (SELECT pid,COALESCE(wait_event,'CPU') wait_event,count(*) cnt, max(itr),min(itr) FROM pg_pid_wait GROUP BY 1,2 ORDER BY cnt DESC) pw GROUP BY 1),
  g AS (SELECT max(ts) ts,max(mx_xid) mx_xid FROM
  (SELECT MAX(state_change) as ts,MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity
    UNION
   SELECT NULL, pg_snapshot_xmax(snapshot)::xid::text::bigint mx_xid FROM pg_gather) a),
  wrk AS (select leader_pid, count(*) from pg_get_activity where leader_pid is not null group by 1),
  itr AS (SELECT max(itr_max) gitr_max FROM w)
  SELECT a.pid,to_jsonb(ROW(d.datname,application_name,client_hostname,sslversion,wrk.count)), a.state,r.rolname "User"
  , CASE WHEN a.leader_pid IS NULL THEN host(client_addr) ELSE 'Worker of ' || a.leader_pid END "client"
  , CASE query WHEN '' THEN '**'||backend_type||' process**' ELSE query END "Last statement"
  , g.ts - backend_start "Connection Since", g.ts - xact_start "Transaction Since", g.mx_xid - backend_xmin::text::bigint "xmin age",
   g.ts - query_start "Statement since",g.ts - state_change "State since", w.waits ||
   CASE WHEN (itr_max - itr_min)::float/itr.gitr_max*2000 - pidwcnt > 0 THEN
    ', Net/Delay*: ' || round(((itr_max - itr_min)::float/itr.gitr_max*2000 - pidwcnt)::numeric*100/2000,2) || '%'
   ELSE '' END waits
  FROM pg_get_activity a 
   LEFT JOIN w ON a.pid = w.pid
   LEFT JOIN itr ON true
   LEFT JOIN g ON true
   LEFT JOIN wrk ON wrk.leader_pid = a.pid
   LEFT JOIN pg_get_roles r ON a.usesysid = r.oid
   LEFT JOIN pg_get_db d on a.datid = d.datid
  ORDER BY "xmin age" DESC NULLS LAST) AS sess
WHERE waits IS NOT NULL OR state != 'idle';

\pset tableattr 'id="tblstmnt"'
\C 'Top Statements'
SELECT DENSE_RANK() OVER (ORDER BY ranksum) "Rank", "Statement",time_pct "DB.time%", calls "Execs",total_time::bigint/calls "Avg.ExecTime","Avg.Reads","C.Hit%" 
,"Avg.Dirty","Avg.Write","Avg.Temp(r)","Avg.Temp(w)" FROM 
(select query "Statement",total_time::bigint
, round((100*total_time/sum(total_time) OVER ())::numeric,2) AS time_pct, DENSE_RANK() OVER (ORDER BY total_time DESC) AS tottrank,calls
,total_time::bigint/calls, DENSE_RANK() OVER (ORDER BY total_time::bigint/calls DESC) as avgtrank
,DENSE_RANK() OVER (ORDER BY total_time DESC)+DENSE_RANK() OVER (ORDER BY total_time::bigint/calls DESC) ranksum
,shared_blks_read/calls "Avg.Reads",
shared_blks_dirtied/calls "Avg.Dirty",
shared_blks_written/calls "Avg.Write",
temp_blks_read/calls "Avg.Temp(r)",
temp_blks_written/calls "Avg.Temp(w)"
,100 * shared_blks_hit / nullif((shared_blks_read + shared_blks_hit),0) as "C.Hit%"
from pg_get_statements) AS stmnts
WHERE tottrank < 10 OR avgtrank < 10 ;

\pset tableattr 'id="tblreplstat"'
WITH M AS (SELECT GREATEST((SELECT(current_wal) FROM pg_gather),(SELECT MAX(sent_lsn) FROM pg_replication_stat))),
g AS (SELECT max(mx_xid) mx_xid FROM
(SELECT MAX(GREATEST(backend_xid::text::bigint,backend_xmin::text::bigint)) mx_xid FROM pg_get_activity
  UNION
 SELECT pg_snapshot_xmax(snapshot)::xid::text::bigint mx_xid FROM pg_gather) a)
SELECT usename AS "Replication User",client_addr AS "Replica Address",pid,state,
 pg_wal_lsn_diff(M.greatest, sent_lsn) "Transmission Lag (Bytes)",pg_wal_lsn_diff(sent_lsn,write_lsn) "Replica Write lag(Bytes)",
 pg_wal_lsn_diff(write_lsn,flush_lsn) "Replica Flush lag(Bytes)",pg_wal_lsn_diff(write_lsn,replay_lsn) "Replay at Replica lag(Bytes)",
 slot_name "Slot",plugin,slot_type "Type",datname "DB name",temporary,active,GREATEST(g.mx_xid-old_xmin::text::bigint,0) as "xmin age",
 GREATEST(g.mx_xid-catalog_xmin::text::bigint,0) as "catalog xmin age", GREATEST(pg_wal_lsn_diff(M.greatest,restart_lsn),0) as "Restart LSN lag(Bytes)",
 GREATEST(pg_wal_lsn_diff(M.greatest,confirmed_flush_lsn),0) as "Confirmed LSN lag(Bytes)"
FROM pg_replication_stat JOIN M ON TRUE
  FULL OUTER JOIN pg_get_slots s ON pid = active_pid
  LEFT JOIN g ON TRUE
  LEFT JOIN pg_get_db ON s.datoid = datid;

\pset tableattr 'id="tblchkpnt"'
SELECT round(checkpoints_req*100/tot_cp,1) "Forced Checkpoint %" ,
round(min_since_reset/tot_cp,2) "avg mins between CP",
round(checkpoint_write_time::numeric/(tot_cp*1000),4) "Avg CP write time (s)",
round(checkpoint_sync_time::numeric/(tot_cp*1000),4)  "Avg CP sync time (s)",
round(total_buffers::numeric*8192/(1024*1024),2) "Tot MB Written",
round((buffers_checkpoint::numeric/tot_cp)*8192/(1024*1024),4) "MB per CP",
round(buffers_checkpoint::numeric*8192/(min_since_reset*60*1024*1024),4) "Checkpoint MBps",
round(buffers_clean::numeric*8192/(min_since_reset*60*1024*1024),4) "Bgwriter MBps",
round(bg.buffers_backend::numeric*8192/(min_since_reset*60*1024*1024),4) "Backend MBps",
round(total_buffers::numeric*8192/(min_since_reset*60*1024*1024),4) "Total MBps",
round(buffers_alloc::numeric/total_buffers,3)  "New buffers ratio",
round(100.0*buffers_checkpoint/total_buffers,1)  "Clean by checkpoints (%)",
round(100.0*buffers_clean/total_buffers,1)   "Clean by bgwriter (%)",
round(100.0*bg.buffers_backend/total_buffers,1)  "Clean by backends (%)",
round(100.0*maxwritten_clean/(min_since_reset*60000 / delay.setting::numeric),2)   "Bgwriter halts (%) per runs",
coalesce(round(100.0*maxwritten_clean/(nullif(buffers_clean,0)/ lru.setting::numeric),2),0)  "Bgwriter halt (%) due to LRU hit",
round(min_since_reset/(60*24),1) "Reset days"
FROM pg_get_bgwriter
CROSS JOIN 
(WITH client AS (SELECT sum(evictions) buffers_backend FROM pg_get_io WHERE btype='c')  
SELECT 
    NULLIF(round(extract('epoch' from (select collect_ts from pg_gather) - stats_reset)/60)::numeric,0) min_since_reset,
    GREATEST(buffers_checkpoint + buffers_clean + COALESCE(client.buffers_backend,pg_get_bgwriter.buffers_backend),1) total_buffers,
    NULLIF(checkpoints_timed+checkpoints_req,0) tot_cp,
    COALESCE(client.buffers_backend,pg_get_bgwriter.buffers_backend) buffers_backend
FROM pg_get_bgwriter,client) AS bg
LEFT JOIN pg_get_confs delay ON delay.name = 'bgwriter_delay'
LEFT JOIN pg_get_confs lru ON lru.name = 'bgwriter_lru_maxpages';

\pset tableattr 'id="tbliostat"'
SELECT
CASE btype WHEN 'a' THEN 'Autovacuum' WHEN 'C' THEN 'Client Backend' WHEN 'G' THEN 'BG writer' WHEN 'b' THEN 'background worker' WHEN 'c' THEN 'Clients' 
  WHEN 'k' THEN 'Checkpointer' WHEN 'w' THEN 'WALSender' ELSE btype END As "Backend", 
sum(reads) "Reads",sum(writes) "Writes",sum(writebacks) "Writebacks", sum(extends) "Extends",sum(hits) "Hits",sum(evictions) "Evictions", sum(reuses) "Reuse", sum(fsyncs) "FSyncs"
FROM pg_get_io 
WHERE reads > 0 OR writes > 0  OR writebacks > 0 or extends > 0 OR hits > 0 OR evictions > 0 OR reuses > 0 OR fsyncs > 0
GROUP BY 1;
%>
<ol id="finditem" style="padding:2em;position:relative">
<h3 style="font: italic bold 2em Georgia, serif;text-decoration: underline; margin: 0 0 0.5em;">Findings:</h3>
<% \pset format aligned
\pset tuples_only on
WITH W AS (SELECT COUNT(*) AS val FROM pg_get_activity WHERE state='idle in transaction')
SELECT CASE WHEN val > 0 
  THEN '<li><b>'||val||' idle-in-transaction</b> session(s). Sessions in idle-in-transaction can cause poor concurrency </li>' 
  ELSE NULL END 
FROM W;
WITH W AS (select last_failed_time,last_archived_time,last_archived_wal from pg_archiver_stat where last_archived_time < last_failed_time)
SELECT CASE WHEN last_archived_time IS NOT NULL
  THEN '<li>WAL archiving is failing since <b>'||last_archived_time||' (duration:'|| (SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) AS c_ts FROM pg_gather) - last_archived_time  ||') onwards</b> '  ||
  CASE WHEN length(last_archived_wal)=24 THEN COALESCE(
  (SELECT ' With estimated size <b>' ||
  pg_size_pretty(((('x'||lpad(split_part(current_wal::TEXT,'/', 1),8,'0'))::bit(32)::bigint - ('x'||substring(last_archived_wal,9,8))::bit(32)::bigint) * 255 * 16^6 + 
  ('x'||lpad(split_part(current_wal::TEXT,'/', 2),8,'0'))::bit(32)::bigint - ('x'||substring(last_archived_wal,17,8))::bit(32)::bigint*16^6 )::bigint)
  FROM pg_gather), ' ') || '</b> behind </li>' ELSE '</li>' END
ELSE NULL END
FROM W;
WITH W AS (select count(*) FILTER (WHERE ct.relkind = 'r') as val, count(*) FILTER (WHERE ct.relkind = 't' ) tval FROM pg_get_index i JOIN pg_get_class ct ON i.indrelid = ct.reloid)
SELECT CASE WHEN val > 10000
  THEN '<li>There are <b>'||val||' Table indexes!</b>  and <b>' || tval || ' Toast Indexes</b> in this database, Only biggest 10000 will be listed in this report under <a href= "#indexes" >Index Info</a>. Please use query No. 11. from the analysis_quries.sql for full details </li>'
  ELSE NULL END
FROM W;
WITH W AS (
 select string_agg(name ||'='||setting,',') as val FROM pg_get_confs WHERE 
 name in ('block_size','max_identifier_length','max_function_args','max_index_keys','segment_size','wal_block_size') AND 
 (name,setting) NOT IN (('block_size','8192'),('max_identifier_length','63'),('max_function_args','100'),('max_index_keys','32'),('segment_size','131072'),('wal_block_size','8192'))
 OR (name = 'wal_segment_size' AND unit ='8kB' and setting != '2048') OR (name = 'wal_segment_size' AND unit ='B' and setting != '16777216')  
)
SELECT CASE WHEN LENGTH(val) > 1
  THEN '<li>Detected Non-Standard Compile/Initialization time parameter changes <b>'||val||' </b>. Custom Compilation is prone to bugs, and it is beyond supportability</li>'
  ELSE NULL END
FROM W;
WITH W AS (
SELECT count(*) cnt FROM pg_get_confs WHERE source IS NOT NULL )
SELECT CASE WHEN cnt < 1
  THEN '<li>Couldn''t get parameter values. Partial gather or corrupt Parameter file(s)</li>'
  ELSE NULL END
FROM W;
SELECT '<li>Parameter '||error ||': '||name||' = '||setting||' in '||sourcefile||'</li>' FROM pg_get_file_confs WHERE error IS NOT NULL;
%>
</ol>
<div id="analdata" hidden>
<% \pset format unaligned
SELECT to_jsonb(r) FROM
(SELECT 
  (select recovery from pg_gather) AS clsr,
  (SELECT to_jsonb(ROW(count(*),COUNT(*) FILTER (WHERE last_vac IS NULL), COUNT(*) FILTER (WHERE b.table_oid IS NULL AND r.n_live_tup != 0 ),COUNT(*) FILTER (WHERE last_anlyze IS NULL))) 
  FROM pg_get_rel r JOIN pg_get_class c ON r.relid = c.reloid AND c.relkind NOT IN ('t','p')
LEFT JOIN pg_tab_bloat b ON c.reloid = b.table_oid) AS tabs,
  (SELECT to_jsonb(ROW(COUNT(*),COUNT(*) FILTER (WHERE CONN < interval '15 minutes' ) )) FROM 
    (WITH g AS (SELECT MAX(state_change) as ts FROM pg_get_activity)
    SELECT pid,g.ts - backend_start CONN
    FROM pg_get_activity
    LEFT JOIN g ON true
    WHERE EXISTS (SELECT pid FROM pg_pid_wait WHERE pid=pg_get_activity.pid)
    AND backend_type='client backend') cn) AS cn,
  (SELECT to_jsonb(ROW(count(*) FILTER (WHERE relkind='p'), count(*) FILTER (WHERE relkind='r' AND relpersistence='u'), max(reloid))) from pg_get_class) as clas,
  (SELECT to_jsonb(ROW(count(*) FILTER (WHERE state='active' AND state IS NOT NULL), 
  count(*) FILTER (WHERE state='idle in transaction'), count(*) FILTER (WHERE state='idle'),
  count(*) FILTER (WHERE state IS NULL), count(*) FILTER (WHERE leader_pid IS NOT NULL) ,
  count(*),   count(distinct backend_type)))
  FROM pg_get_activity) as sess,
  (WITH curdb AS (SELECT 
  CASE WHEN (SELECT COUNT(*) FROM pg_srvr) > 0 
    THEN (SELECT trim(both '\"' from substring(connstr from '\"\w*\"')) "curdb" FROM pg_srvr WHERE connstr like '%to database%') ELSE (SELECT 'template1' "curdb")
  END),
  cts AS (SELECT COALESCE((SELECT COALESCE(collect_ts,(SELECT max(state_change) FROM pg_get_activity)) FROM pg_gather),current_timestamp) AS c_ts)
  SELECT to_jsonb(ROW(curdb,COALESCE(pg_get_db.stats_reset,pg_get_wal.stats_reset),c_ts,days))
  FROM  curdb LEFT JOIN pg_get_db ON pg_get_db.datname=curdb.curdb
  LEFT JOIN pg_get_wal ON true
  LEFT JOIN LATERAL (SELECT GREATEST((EXTRACT(epoch FROM(c_ts- COALESCE(pg_get_db.stats_reset,pg_get_wal.stats_reset)))/86400)::bigint,1) as days FROM cts) AS lat1 ON TRUE
  LEFT JOIN cts ON true) as dbts,
  (WITH maxmxid AS (SELECT max(mxidage) FROM pg_get_db),
  topdbmx AS (SELECT array_agg(datname),maxmxid.max FROM pg_get_db JOIN maxmxid ON pg_get_db.mxidage=maxmxid.max AND pg_get_db.mxidage > 1000 GROUP BY 2)
  SELECT to_jsonb(ROW(array_agg,max)) FROM topdbmx) AS mxiddbs,
  (SELECT json_agg(pg_get_ns) FROM  pg_get_ns) AS ns,
  (SELECT json_agg(pg_get_tablespace) FROM pg_get_tablespace) AS tbsp,
  (SELECT to_jsonb((extract (EPOCH FROM (collect_ts - last_archived_time)), pg_wal_lsn_diff( current_wal,
  (coalesce(nullif(CASE WHEN length(last_archived_wal) < 24 THEN '' ELSE ltrim(substring(last_archived_wal, 9, 8), '0') END, ''), '0') || '/' || substring(last_archived_wal, 23, 2) || '000001'        ) :: pg_lsn )
  , last_archived_wal, last_archived_time::text || ' (' || CASE WHEN EXTRACT(EPOCH FROM(collect_ts - last_archived_time)) < 0 THEN 'Right Now'::text ELSE (collect_ts - last_archived_time)::text END  || ')'))
  FROM  pg_gather,  pg_archiver_stat) AS arcfail,
  (SELECT to_jsonb(ROW(max(setting) FILTER (WHERE name = 'archive_library'), max(setting) FILTER (WHERE name = 'cluster_name'),count(*) FILTER (WHERE source = 'command line'))) FROM pg_get_confs) AS params,
  (WITH g AS (SELECT collect_ts,pg_start_ts,reload_ts,to_timestamp ( systemid >> 32 ) init_ts from pg_gather),
    r AS (SELECT LEAST(min(last_vac),min(last_anlyze)) known_ts FROM pg_get_rel)
  SELECT CASE WHEN (g.init_ts IS NULL OR g.reload_ts - g.init_ts > '80 minutes'::interval) AND ( r.known_ts > g.reload_ts OR r.known_ts IS NULL) AND g.collect_ts - g.reload_ts < '10 days'::interval 
  THEN g.reload_ts END crash_ts FROM g,r) crash,
  (WITH blockers AS (select array_agg(victim_pid) OVER () victim,blocking_pids blocker from pg_get_pidblock),
   ublokers as (SELECT unnest(blocker) AS blkr FROM blockers)
   SELECT json_agg(blkr) FROM ublokers
   WHERE NOT EXISTS (SELECT 1 FROM blockers WHERE ublokers.blkr = ANY(victim))) blkrs,
  (select json_agg((victim_pid,blocking_pids)) from pg_get_pidblock) victims,
  (SELECT  to_jsonb(( EXTRACT(epoch FROM (end_ts - collect_ts)),  pg_wal_lsn_diff(end_lsn, current_wal) * 60 * 60 / EXTRACT( epoch FROM (end_ts - collect_ts) ),
  wal_bytes/(extract (EPOCH FROM  (collect_ts - stats_reset))/3600)))
  FROM pg_gather JOIN pg_gather_end ON true
   LEFT JOIN pg_get_wal ON true) sumry,
  (SELECT json_agg((relname,maint_work_mem_gb)) FROM (SELECT relname,n_live_tup*0.2*6 maint_work_mem_gb 
   FROM pg_get_rel JOIN pg_get_class ON n_live_tup > 894784853 AND pg_get_rel.relid = pg_get_class.reloid 
   ORDER BY 2 DESC LIMIT 3) AS wmemuse) wmemuse,
   (WITH w AS (SELECT pid,count(*) cnt, max(itr) itr_max,min(itr) itr_min FROM pg_pid_wait group by 1),
   g AS (SELECT max(itr_max) gmax_itr FROM w)
  SELECT to_jsonb(ROW(SUM(((itr_max - itr_min)::float/gmax_itr)*2000 - cnt),max(gmax_itr),count(pid))) FROM w,g
   WHERE ((itr_max - itr_min)::float/gmax_itr)*2000 - cnt > 0) netdlay,
   (SELECT to_jsonb(ROW(count(*) FILTER (WHERE indisvalid=false)
   ,count(*) FILTER (WHERE numscans=0 AND tst.toastid IS NULL) --Unused Indexes of user tables
   ,count(*) FILTER (WHERE numscans=0 AND tst.toastid > 16384) --Unused TOAST index of user tables
   ,count(*) FILTER (WHERE tst.toastid IS NULL) --TOTAL User/Regular indexes
   ,count(*) FILTER (WHERE tst.toastid > 16384) --TOTAL Toast Indexes
   ,sum(size) FILTER (WHERE numscans=0)))
    FROM pg_get_index i
    JOIN pg_get_class ct ON i.indrelid = ct.reloid
    LEFT JOIN pg_get_toast tst ON ct.reloid = tst.toastid) induse,
    (WITH pkuk AS (SELECT indrelid,bool_or(indisprimary) pk,bool_or(indisunique) uk FROM pg_get_index GROUP BY indrelid)
    SELECT to_jsonb(ROW(COUNT(*) FILTER (WHERE pkuk.pk IS NULL OR NOT pkuk.pk), COUNT(*) FILTER (WHERE pkuk.uk IS NULL OR NOT pkuk.uk)))
    FROM pg_get_class c LEFT JOIN pkuk ON pkuk.indrelid = c.reloid WHERE c.relkind IN ('r')) nokey,
   (SELECT to_jsonb(ROW(sum(tab_ind_size) FILTER (WHERE relid < 16384),count(*))) FROM pg_get_rel) meta
) r;
%>
</div>
</div> <!--End of "sections"-->
<footer>End of <a href="https://github.com/jobinau/pg_gather">pgGather</a> Report</footer>
<script type="text/javascript">
//Global object to hold json values passed from the SQL analysis
obj={};
//pg_gather version
ver="28";
docurl="https://jobinau.github.io/pg_gather/";
//Currently supported PostgreSQL versions, Extensions
meta={pgvers:["12.22","13.18","14.15","15.10","16.6","17.2"],commonExtn:["plpgsql","pg_stat_statements"],riskyExtn:["citus","tds_fdw"]};
mgrver="";
walcomprz="";
datadir=""; //data directory is needed for understanding the tablespaces.
//Global variable to hold autovacuum_freeze_max_age, so that each table can be compared
autovacuum_freeze_max_age = 0;
//Global varaible to hold all emitted findings from different sections, which will finally presented in Findings section
let strfind = "";

//total DB size
totdb=0;
//Number of CPUs and Memory. Since many parameter are based on CPU and memory better to hold as a global variable.
totCPU=0;
totMem=0;
//Prepare the list of blockers and Victims
let blokers = []
let blkvictims = []
//Parameter array with each parameter ("param") current value ("val"), recomendations.
let params = []


//When the DOM is ready
document.addEventListener("DOMContentLoaded", () => {
obj=JSON.parse( document.getElementById("analdata").innerText);
// New code for preparting victims and blockers
if (obj.victims !== null){
//each victim will have associated blockers like : victim1 : blocker1, blocker2 
//prepare the list of victims
obj.victims.forEach(function(victim){
  blkvictims.push(victim.f1);
});
//prepare the list of blockers
obj.victims.forEach(function(victim){
  //for each victim there can be multiple blockers
  victim.f2.forEach(function(blker){
    //if the blocker is not appearing in victim's list and blocker is not allready added to blockers list, add 
    if (blkvictims.indexOf(blker) == -1 && blokers.indexOf(blker) == -1) blokers.push(blker);
  });
});
}
checkgather();
checkpars();
checktabs();
checkindex();
checkdbs();
checkdbtime();
checkextn();
checkhba();
checkconns();
checkusers();
checksess();
checkstmnts();
checkchkpntbgwrtr();
checkiostat()
checkfindings();
});

window.onload = function() {
// can also use window.addEventListener('load', (event) => {
//  ["tabInfo","IndInfo","params","sections"].forEach(function(t) {document.getElementById(t).style="display:table";})
  document.getElementById("sections").style="display:table";
  document.getElementById("busy").style="display:none";
};

//Check the data collection of pg_gather
function checkgather(){
  const trs=document.getElementById("tblgather").rows
  let days,xmax=0;
  for (let i = 0; i < trs.length; i++) {
    val = trs[i].cells[1];
    switch(trs[i].cells[0].innerText){
      case "pg_gather" :
        val.innerText = val.innerText + "-v" + ver;
        break;
      case "Collected By" :
        if (val.innerText.slice(-2) < ver ) { val.classList.add("warn"); val.title = "Data is collected using old/obsolete version of gather.sql file. Please use v" + ver; 
        strfind += "<li>Data collected using old/obsolete version (v"+ val.innerText.slice(-2) + ") of gather.sql file. Please use v" + ver + " <a href='"+ docurl +"versionpolicy.html'>Details</a></li>";
        }
        break;
      case "In recovery?" :
        if(val.innerText == "true") {val.classList.add("lime"); val.title="Data collected at standby"; obj.primary = false;}
        else obj.primary = true;  //store that the instance is primary into obj
        break;
      case "System" :   //under assumption that columns will be sorted alphabetically. So this comes before "Time line"
        let startIndex = val.innerText.indexOf("(") + 1;
        days = parseInt(val.innerText.substring(startIndex,val.innerText.indexOf(" days", startIndex)));
        break;
      case "Latest xid" :
        xmax = parseInt(val.innerText);
        break;
      case "Oldest xid ref" :
        val.innerText += " (" + (xmax - parseInt(val.innerText)).toString() + " xids old)";
        break;
      case "Time Line" :
        let Failover = parseInt(val.innerText.substring(0,val.innerText.indexOf(" (")))-1;
        if (days > 30 && Failover > 5){
          let MTBF = days/Failover;
          if (MTBF < 180){
            val.classList.add("warn"); val.title = "Poor MTBF / Availability number. There were " + Failover + " failovers in " + days + " days." ;
            strfind += "<li><b>Poor MTBF / Availability number: "+ Math.round(MTBF) +" days!</b>. There were " + Failover + " failovers in " + days + " days</li>";
          }
        }
    }
  }
}

//check the obj content and display findings messages accordingly
function checkfindings(){
 //if the number of background processes from pg_stat_activity is less than 4, then it indicates the user don't have access to pg_stat* views properly
 let tmpstr = ""; //temporary string for hoding info during the string formatting
 if (obj.sess.f7 < 4){ 
  strfind += "<li><b>The pg_gather data is collected by a user who don't have necessary privilege OR Content of the output file (out.txt) is copy-pasted destroying the TSV format</b><br/><b>1.</b>Please run the gather.sql as a privileged user (superuser, rds_superuser etc.) or some account with pg_monitor privilege and <b>2.</b> Please provide the output file as it is without copy-pasting</li>"
  document.getElementById("tableConten").title="Waitevents data will be growsly incorrect because the pg_gather data is collected by a user who don't have proper privilege OR content of output file is copy-pasted. Please refer the Findings section";
  document.getElementById("tableConten").caption.innerHTML += "<br/>" + document.getElementById("tableConten").title
  document.getElementById("tableConten").classList.add("high");
 }
 if (obj.cn.f1 > 0){
    strfind +="<li><b>" + obj.cn.f2 + " / " + obj.cn.f1 + " connections </b> in use are new. "
    if (obj.cn.f2 > 9 || obj.cn.f2/obj.cn.f1 > 0.7 ){
      strfind+="Please consider this for improving connection pooling"
    } 
    strfind += "</li>";
 }
 if (obj.induse.f1 > 0 ) strfind += "<li><b>"+ obj.induse.f1 +" Invalid Index(es)</b> found. Recreate or drop them. Refer <a href='"+ docurl +"InvalidIndexes.html'>Details</a></li>";
 if (obj.induse.f2 > 0 ) strfind += "<li><b>"+ obj.induse.f2 +" regular user indexes and " + obj.induse.f3 + " Toast Indexes are unused,</b> out of " + obj.induse.f4 + " user indexes and " + obj.induse.f5 + " Toast Indexes . Currently the unused indexes needs <b>additional "+ bytesToSize(obj.induse.f6) +" to cache</b>. <a href='"+ docurl +"unusedIndexes.html'>Details</a></li>";
 if (obj.mxiddbs !== null) strfind += "<li> Multi Transaction ID age : <b>" + obj.mxiddbs.f2 + "</b> for databases  <b>" + obj.mxiddbs.f1 + "</b> <a href='"+ docurl +"mxid.html'>Details</a></li>"
 if (obj.clas.f1 > 0) strfind += "<li><b>"+ obj.clas.f1 +" Natively partitioned tables</b> found. Tables section could contain partitions</li>";
 if (obj.clas.f2 > 0) strfind += "<li><b>"+ obj.clas.f2 +" Unlogged tables found.</b> These tables and associated indexes are ephemeral. <a href='"+ docurl +"unloggedtables.html'>Details</a></li>";
 if (obj.params.f3 > 10) strfind += "<li> Patroni/HA PG cluster :<b>" + obj.params.f2 + "</b></li>"
 if (obj.crash !== null) strfind += "<li>Detected a <b>suspected crash / unclean shutdown around : " + obj.crash + ".</b> Please check the PostgreSQL logs</li>"
 if (obj.nokey.f1 > 0) strfind += "<li><b>"+ obj.nokey.f1 +" Tables without Primary Key</b> and <b>"+ obj.nokey.f2 +" Tables without niether Primary key nor Unique keys</b> found. Please refer <a href='"+ docurl +"pkuk.html'>Details</a></li>";
 if (obj.netdlay.f1 > 10) {
   if (obj.netdlay.f1 / obj.netdlay.f2 * 100 > 20 ){ strfind += "<li> There are <b>"+ obj.netdlay.f3 +" Sessions with considerable Net/Delays</b>"
   tmpstr = "Total <a href='"+ docurl +"NetDelay.html'>Net/Delay<a>"
   if (obj.netdlay.f1 / obj.netdlay.f2 > 1){
      tmpstr += " is <b>" + (obj.netdlay.f1 / obj.netdlay.f2).toFixed(1) + "Times ! </b> of overall server activity. which is huge"
   }else if(obj.netdlay.f1 / obj.netdlay.f2 > 0.1){
    tmpstr += " is equivalent to <b>" + (obj.netdlay.f1 * 100 / obj.netdlay.f2).toFixed(2) + "% </b> of server activity"
   }
   if (tmpstr.length > 100 ){
    strfind += "<li>" + tmpstr + "</li>"
    document.getElementById("tableConten").tFoot.children[0].children[0].innerHTML += tmpstr
   }
  }
  for (let item of params) {  //Add all Parameter related warnigns.
    if (typeof item.warn != "undefined"){
     strfind += "<li>" + item.warn +"</li>";
    }
  }
 }
 if(obj.clsr){
  strfind += "<li>PostgreSQL is in Standby mode or in Recovery</li>";
 }else{
  if ( obj.tabs.f2 > 0 ) strfind += "<li> <b>No vacuum info for " + obj.tabs.f2 + "</b> tables/objects </li>";
  if ( obj.tabs.f3 > 0 ) strfind += "<li> <b>No statistics available for " + obj.tabs.f3 + " tables/objects</b>, query planning can go wrong. <a href='"+ docurl +"missingstats.html'>Learn Details</a></li>";
  if ( obj.tabs.f1 > 10000) strfind += "<li> There are <b>" + obj.tabs.f1 + " tables/objects</b> in the database. Only the biggest 10000 will be displayed in the report. Avoid too many tables/objects in single database. <a href='"+ docurl +"table_object.html'>Learn Details</a></li>";
  if (obj.arcfail != null) { //entire information can go missing if no record comes to table : pg_gather, which could happen in aurora
   if (obj.arcfail.f1 == null) strfind += "<li>No working WAL archiving and backup detected. PITR may not be possible</li>";
   if (obj.arcfail.f1 > 300) strfind += "<li>No WAL archiving happened in last "+ Math.round(obj.arcfail.f1/60) +" minutes. <b>Archiving could be failing</b>; please check PG logs</li>";
   //Negative values for obj.arcfail.f2 should be expected because current LSN capture happens at the beginining
   if (obj.arcfail.f2 && obj.arcfail.f2 > 0) strfind += "<li>WAL archiving is <b>lagging by "+ bytesToSize(obj.arcfail.f2,1024)  +"</b>. Last archived WAL is : <b>"+ obj.arcfail.f3 +"</b> at "+ obj.arcfail.f4 +"</li>";
  }
  if (obj.wmemuse !== null && obj.wmemuse.length > 0){ strfind += "<li> Biggest <code>maintenance_work_mem</code> consumers are :<b>"; obj.wmemuse.forEach(function(t,idx){ strfind += (idx+1)+". "+t.f1 + " (" + bytesToSize(t.f2) + ")    " }); strfind += "</b></li>"; }
  if (obj.victims !== null && obj.victims.length > 0) strfind += "<li><b>" + obj.victims.length + " session(s) blocked.</b></li>"
  if (obj.sumry !== null){ strfind += "<li>Data collection took <b>" + obj.sumry.f1 + " seconds. </b>";
     if ( obj.sumry.f1 < 23 ) strfind += "System response is good</li>";
     else if ( obj.sumry.f1 < 28 ) strfind += "System response is below average</li>";
     else strfind += "System response appears to be poor</li>";
     strfind += "<li>Current WAL generation rate is <b>" + bytesToSize(obj.sumry.f2) + " / hour</b>"; 
     if (obj.sumry.f3 !== null ) strfind += ", Long term average WAL generation rate is <b>" + bytesToSize(obj.sumry.f3) + "/hour</b></li>"; 
     else strfind += "</li>" }
  if ( mgrver.length > 0 &&  mgrver < Math.trunc(meta.pgvers[0])) strfind += "<li>PostgreSQL <b>Version : " + mgrver + " is outdated (EOL) and not supported</b>, Please upgrade urgently</li>";
  if ( mgrver >= 15 && ( walcomprz == "off" || walcomprz == "on")) strfind += "<li>The <b>wal_compression is '" + walcomprz + "' on PG"+ mgrver +"</b>, consider a good compression method (lz4,zstd)</li>"
  if (obj.ns !== null){
   let tempNScnt = obj.ns.filter(n => n.nsname.indexOf("pg_temp") > -1).length + obj.ns.filter(n => n.nsname.indexOf("pg_toast_temp") > -1).length ;
   tmpfind = "<li><b>" + (obj.ns.length - tempNScnt).toString()  + " Regular schema(s) and " + tempNScnt + " temporary schema(s)</b> in this database. <a href='"+ docurl +"schema.html'> Details<a>";
   if (tempNScnt > 0 && obj.clas.f3 > 50000) tmpfind += "<br>Currently oid of pg_class stands at " + Number(obj.clas.f3).toLocaleString("en-US") + " <b>indicating the usage of temp tables</b>"
   strfind += tmpfind + "</li>";
  }
  if (obj.meta.f1 > 15728640){ //metadata more than 15MB
    strfind += "<li>" + "The catalog metadata is :<b>" + bytesToSize(obj.meta.f1) + " For " + obj.meta.f2 + " objects. </b><a href='"+ docurl +"catalogbloat.html'> Details<a></li>"
  }
 }
  //update the findings section
  document.getElementById("finditem").innerHTML += strfind;

  //Add footer to database details table at the top
  var el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='9'>**Averages are Per Day. Total size of "+ (document.getElementById("dbs").tBodies[0].rows.length - 1) +" DBs : "+ bytesToSize(totdb) +"</th>";
  dbs=document.getElementById("dbs");
  dbs.appendChild(el);
}

function checkconns(){
  tab=document.getElementById("tblcs");
  tab.caption.innerHTML=''<span>DB Connections</span>'';
  const trs=tab.rows
  let nonssl=0;
  for (var i=1;i<trs.length;i++){
    tr=trs[i];
    if (tr.cells[7].innerText > 0) nonssl += parseInt(tr.cells[7].innerText);
    if (tr.cells[5].innerText > 20 && tr.cells[7].innerText/tr.cells[5].innerText > 0.5 ){
      tr.cells[7].classList.add("warn");
      tr.cells[7].title="Large precentage of unencrypted connections"
    }
  }
  if (nonssl > 10) strfind += "<li>Number of unencrypted connections : <b>"+ nonssl +"</b></li>"
  el=document.createElement("tfoot");  //footer element to connection details
  el.innerHTML = "<th colspan='7'>Active: "+ obj.sess.f1 +", Idle-in-transaction: " + obj.sess.f2 + ", Idle: " + obj.sess.f3 + ", Background: " + obj.sess.f4 + ", Workers: " + obj.sess.f5 + ", Total: " + obj.sess.f6 + "</th>";
  tab.appendChild(el);
}

//Event listeners for changing the CPU, Memory, Storage, Workload and Filesystem. Get the new recommendation
["cpus","mem","strg","wrkld","flsys"].forEach(function(t) {document.getElementById(t).addEventListener("change", (event) => { getreccomendation(); })});

function getreccomendation(){
  totMem = document.getElementById("mem").value;
  totCPU = document.getElementById("cpus").value;
  checkpars();
  let reccomandations = document.getElementById("paramtune").children[1];
  let reccos = "";
  for (let item of params) {
    if (typeof item.suggest != "undefined"){
     reccos += "<li>" + item.param + " = " + item.suggest + "&emsp;<a href='"+ docurl +"params/" + item.param +".html'>#Explanation</a></li>"
    }
  }
  reccomandations.innerHTML = reccos;
}

function flash(msg){
  var el=document.createElement("div");
  el.setAttribute("id", "cur");
  el.setAttribute("style", "position: fixed;top: 50%;left: 50%;transform: translate(-50%, -50%);");
  el.textContent = msg;
  document.body.appendChild(el);
  setTimeout(() => { el.remove();},2000);
}

//Copy the parameter recommendations as HTML
function copyashtml(){
  let elem = document.getElementById("paramtune");
  let paramtune = elem.cloneNode(true); //Deep clone and set style for the clone.
  paramtune.style="font-weight:initial;line-height:1.5em;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em;box-shadow: 0px 20px 30px -10px grey";
  navigator.clipboard.writeText(paramtune.outerHTML);
  flash("Parameter recommendations are copied to clipboard as HTML code");
}

function copyrichhtml(){
  let elem = document.getElementById("paramtune")
  let paramtune = elem.cloneNode(true); //Deep clone and set style for the clone.
  paramtune.style="font-weight:initial;line-height:1.5em;background-color:#FAFFEA;border: 2px solid blue; border-radius: 5px; padding: 1em;box-shadow: 0px 20px 30px -10px grey";
  const clipboardItem = new ClipboardItem({	"text/plain": new Blob([paramtune.innerText],	{ type: "text/plain" }),
              "text/html": new Blob([paramtune.outerHTML],{ type: "text/html" })});
  navigator.clipboard.write([clipboardItem]);
  flash("Parameter recommendations are copied to clipboard as HTML Rich object");
}

//Convert bytes into human readable formats
function bytesToSize(bytes,divisor = 1000) {
  const sizes = ["B","KB","MB","GB","TB"];
  if (bytes == 0) return "0B";
  const i = parseInt(Math.floor(Math.log(bytes) / Math.log(divisor)), 10);
  if (i === 0) return bytes + sizes[i];
  return (bytes / (divisor ** i)).toFixed(1) + sizes[i]; 
}

//Set the tooltips for the Table head row.
function setheadtip(th,tips){
  for (i in tips) th.cells[i].title = tips[i];
}

//add key and value to json string
function updateJson(jsonString, key, value) {
  const jsonObject = JSON.parse(jsonString); // Parse the JSON string into a JavaScript object
  jsonObject[key] = value; // Add the new key-value pair
  return JSON.stringify(jsonObject); // Convert the updated object back to a JSON string
}


//Convert time format seperated by colon (:) to seconds for comparision
function DurationtoSeconds(duration){
    let days=0,dayIdx
    dayIdx=duration.indexOf("days")
    if(dayIdx>0){
      days=parseInt(duration.substring(0,dayIdx))
      duration=duration.substring(dayIdx+5)
    }
    const [hours, minutes, seconds] = duration.split(":");
    return days * 24 * 60 * 60 +(hours) * 60 * 60 + Number(minutes) * 60 + Number(seconds);
};

//******************* New Parameter Despatch table implimentation v22 *******************/
var paramDespatch = {
  archive_mode : function(rowref){
    val=rowref.cells[1];
    if(obj.primary  == true && val.innerHTML == "off"){ val.classList.add("warn"); val.title="Primary server without WAL archiving configured. No PITR possible"}
  },
  archive_command : function(rowref) {
    val=rowref.cells[1];
    if (obj.params !== null && obj.params.f1 !== null && obj.params.f1.length > 0) { val.classList.add("warn"); val.title="archive_command won't be in-effect, because archive_library : " + obj.arclib + " is specified"  }
    else if (val.innerText.length < 5) {val.classList.add("warn"); val.title="A valid archive_command is expected for WAL archiving, unless archive library is used" ; }
  },
  autovacuum : function(rowref) {
    val=rowref.cells[1];
    if(val.innerText != "on") { val.classList.add("warn"); val.title="Autovacuum must be on" }
  },
  autovacuum_max_workers : function(rowref) {
    val=rowref.cells[1];
    if(val.innerText > 3) { val.classList.add("warn"); val.title="High number of workers causes each workers to run slower because of the cost limit" ;
      let param = params.find(p => p.param === "autovacuum_max_workers");
      param["suggest"] = "3";
    }
  },
  autovacuum_vacuum_cost_limit: function(rowref){
    val=rowref.cells[1];
    if(val.innerText > 800 || val.innerText == -1 ) { val.classList.add("warn"); val.title="Better to specify this with a value less than 800" }
  },
  autovacuum_freeze_max_age: function(rowref){
    val=rowref.cells[1];
    autovacuum_freeze_max_age = Number(val.innerText);  //Store the value to global variable
    if (autovacuum_freeze_max_age > 800000000) val.classList.add("warn");
  },
  bgwriter_lru_maxpages: function(rowref){
    let param = params.find(p => p.param === "bgwriter_lru_maxpages");
    if (typeof param["suggest"] != "undefined"){
      val = val=rowref.cells[1];
      val.classList.add("warn"); 
      val.title="bgwriter_lru_maxpages is too low. Increase this to :" + param["suggest"];
    }
  },
  checkpoint_timeout: function(rowref){
    val=rowref.cells[1];
    if(val.innerText < 1200) { val.classList.add("warn"); val.title="Too small gap between checkpoints"}
  },
  data_directory: function(rowref){
    datadir=val.innerText;
  },
  deadlock_timeout: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); }, //TODO: Warn if is more than 1 mintue
  effective_cache_size: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024); }, 
  huge_pages: function(rowref){ 
    val=rowref.cells[1]; 
    if (val.innerText != "on" ) {
      val.classList.add("warn");
      let param = params.find(p => p.param === "huge_pages");
      param["suggest"] = "on";
    } else val.classList.add("lime"); 
  },
  huge_page_size: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  hot_standby_feedback: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); },
  idle_session_timeout:function(rowref){ 
    val=rowref.cells[1]; 
    if (val.innerText > 0) { val.classList.add("warn"); val.title="It is dangerous to use idle_session_timeout. Avoid using this" }
  },
  idle_in_transaction_session_timeout: function(rowref){ 
    val=rowref.cells[1]; 
    if (val.innerText == 0){ val.classList.add("warn"); val.title="Highly suggestable to use atleast 5min to prevent application misbehaviour" }
    let param = params.find(p => p.param === "idle_in_transaction_session_timeout");
    param["suggest"] = "'5min'";
  },
  jit: function(rowref){ val=rowref.cells[1]; if (val.innerText=="on") { 
    val.classList.add("warn");
    val.title="Avoid JIT globally (Disable), Use only at smaller scope" 
    let param = params.find(p => p.param === "jit");
    param["suggest"] = "off";
  }},
  log_temp_files: function(rowref){
    val = val=rowref.cells[1];
    let param = params.find(p => p.param === "log_temp_files");
    if (typeof param["suggest"] != "undefined"){
      val.classList.add("warn"); 
      val.title="Heavy temporary file generation is detected. Consider setting log_temp_files=" + param["suggest"] ;
    } else if ((param["val"] > -1)){
      val.classList.add("lime");
      val.title="log_temp_files is already set. Analyze PostgreSQL log for problematic SQLs. Adjust parameter value if required";
    }
  },
  log_truncate_on_rotation: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "log_truncate_on_rotation");
    if (val.innerText == "off")  param["suggest"] = "on";
  },
  log_lock_waits: function(rowref){
    val=rowref.cells[1]; let param = params.find(p => p.param === "log_lock_waits");
    if(val.innerText == "off") param["suggest"] = "on";
  },
  lock_timeout: function(rowref){
    val=rowref.cells[1]; let param = params.find(p => p.param === "lock_timeout");
    if(val.innerText == "0") param["suggest"] = "'1min'";
  },
  maintenance_work_mem: function(rowref){ val=rowref.cells[1]; val.classList.add("lime"); val.title=bytesToSize(val.innerText*1024,1024); },
  max_connections: function(rowref){
    val=rowref.cells[1];
    val.title="Avoid value exceeding 10x of the CPUs"
    if( totCPU > 0 ){
      if(val.innerText > 10 * totCPU) { 
        val.classList.add("warn"); val.title="If there is only " + totCPU + " CPUs value above " + 10*totCPU + " Is not recommendable for performance and stability";
        let conns = params.find(p => p.param === "max_connections");
        conns["suggest"] = 10 * totCPU;
      }else { val.classList.remove("warn"); val.classList.add("lime"); val.title="Current value is good" }
    } else if (val.innerText > 500) val.classList.add("warn")
      else val.classList.add("lime")
  },
  max_standby_archive_delay: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "max_standby_archive_delay");
    console.log(this);
    if (val.innerText > 30000){ param["suggest"] = "30000"; val.classList.add("lime") }
  },
  max_standby_streaming_delay: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "max_standby_streaming_delay");
    console.log(val.innerText);
    if (val.innerText > 30000){ param["suggest"] = "30000"; val.classList.add("lime");}
  },
  max_wal_size: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024*1024,1024);
    if(val.innerText < 8192) { val.classList.add("warn"); val.title += ",Too low for production use" }
    else val.classList.add("lime");
  },
  min_wal_size: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024*1024,1024);
    if(val.innerText < 2048) {val.classList.add("warn"); val.title+=",Too low for production use" }
    else val.classList.add("lime");
  },
  random_page_cost: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "random_page_cost");
    let strg = document.getElementById("strg").value;
  if ( strg == "ssd" ){
    if (val.innerText > 1.2){param["suggest"] = "1.1";   val.classList.add("warn");}
    else val.classList.add("lime");
  } else if ( strg == "san" ){
    if (val.innerText > 1.5){ param["suggest"] = "1.5";   val.classList.add("warn");}
    else val.classList.add("lime");
  } else { param["suggest"] = "4"; val.classList.add("lime")}; 
  },
  wal_keep_size: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024*1024,1024);
    val.classList.add("lime");
  },
  seq_page_cost: function(rowref){
    val=rowref.cells[1];
    let param = params.find(p => p.param === "seq_page_cost");
    if (val.innerText != 1){ 
      param["suggest"] = "1"; val.classList.add("warn"); val.title="Avoid changing seq_page_cost value to anything other than 1, unless there is an unavoidable reason"; 
      param["warn"] = "seq_page_cost is specified as <b>" + val.innerText + "</b>. " + val.title; 
    }
  },
  server_version: function(rowref){
    val=rowref.cells[1];
    let setval = val.innerText.split(" ")[0]; mgrver=setval.split(".")[0];
    let sver_ver = params.find(p => p.param === "server_version");
    if ( mgrver < Math.trunc(meta.pgvers[0])){
      val.classList.add("warn"); val.title="PostgreSQL Version is outdated (EOL) and not supported";
      sver_ver["warn"] = "Running Unsupported PostgreSQL Version " + mgrver;
    } else {
      meta.pgvers.forEach(function(t){
        if (Math.trunc(setval) == Math.trunc(t)){
          if (t.split(".")[1] - setval.split(".")[1] > 0 ) { val.classList.add("warn"); val.title= t.split(".")[1] - setval.split(".")[1] + " minor version updates are pending. Please upgrade ASAP"; 
           sver_ver["warn"] = "PostgreSQL <b>Version"+ val.innerText + ".</b> " + val.title;
          }
        }
      })  
    }
    if(val.classList.length < 1) val.classList.add("lime");  //if no problems found, just highlight the data
  },
  shared_buffers: function(rowref){
    val=rowref.cells[1];
    val.classList.add("lime"); val.title=bytesToSize(val.innerText*8192,1024);
    //if RAM is is not given, and shared_bffer is above 128MB. Assume that shared_buffer is 1/4th of the RAM and do revese calculation to get RAM
    if(parseFloat(document.getElementById("mem").value) < "0.2" ){
      document.getElementById("mem").value = val.innerText*8*4/(1024*1024);
      totMem = val.innerText*8*4/(1024*1024);
    }
    if( totMem > 0 && ( totMem < val.innerText*8*0.2/1048576 || totMem > val.innerText*8*0.3/1048576 ))
      { val.classList.add("warn"); val.title="Approx. 25% of available memory is recommended, current value of " + bytesToSize(val.innerText*8192,1024) + " appears to be off"; 
      let param = params.find(p => p.param === "shared_buffers");
      param["suggest"]= "'"+ bytesToSize(totMem*1000000000*0.25) + "'";
      }
  },
  statement_timeout : function(rowref){
    val=rowref.cells[1];
    if(rowref.cells[3].innerText == "session" && rowref.cells[4].innerText.indexOf("/") < 0 ){
      rowref.cells[3].innerText= "default"; val.innerText="0";
      val.classList.add("warn"); val.title="It is important to set a value globally to avoid long running sessions and associated problems"
      let tmout = params.find(p => p.param === "statement_timeout");
      tmout["suggest"] = "'4h'";
      //Actual value need to be considering OLTP/OLAP workload
    }
  },
  synchronous_standby_names: function(rowref){
    val=rowref.cells[1];
    if (val.innerText.trim().length > 0){ val.classList.add("warn"); val.title="Synchronous Standby can cause session hangs, and poor performance"; }
  },
  track_io_timing: function(rowref){
    val=rowref.cells[1];
    if (val.innerText == "off"){
      let param = params.find(p => p.param === "track_io_timing");
      param["suggest"] = "on";
    }
  },
  wal_compression: function(rowref){
    val=rowref.cells[1]; val.classList.add("lime"); walcomprz = val.innerText; //highlight and update the global variable
  },
  work_mem: function(rowref){
    val=rowref.cells[1];
    val.title=bytesToSize(val.innerText*1024,1024) ;
    if(val.innerText > 98304){ val.classList.add("warn"); val.title += ", Avoid global settings above 64MB to avoid memory related issues"  }
    else val.classList.add("lime");
    let conns = params.find(p => p.param === "max_connections");
    let wmem = params.find(p => p.param === "work_mem");
    // 1/5th of the RAM can be given for total work_mem. So 1/5th of RAM / max_connections
    if ( totMem > 0.2 && conns.val > 1){
      wmem["suggest"] = "'" + Math.min(parseInt(totMem*1024/(5*parseInt(conns.val)) + 4 ),64) + "MB'";
    }
  },
  default : function(rowref) {}  //NOT used. remove after Test of time
};

// Interface for parameter evaluation, Second paramter is optional and can be called like : evalParam("autovacuum_vacuum_cost_limit"); 
var evalParam = function(param,rowref = null) {
  if (rowref != null && rowref.id == "") rowref.id=param;   //if rowref don't have an id, add it, This happens in the first invocation.
  else rowref = document.getElementById(param);  //No need to check like : if (rowref == null), because subsequent calls to the function is not expecting rowref
  //OLD code to call default function : var param = paramDespatch.hasOwnProperty(param) ? param : "default"
  //if despatcher has the specific paramteter section (only few parameters have)
  if (paramDespatch.hasOwnProperty(param)){ 
    let paramJson = {}; paramJson["param"] = param; paramJson["val"] = rowref.cells[1].innerText; //Create a json object with parameter and value
    params.push(paramJson);    //Push the json object o params array
    paramDespatch[param](rowref);   //Finally calle the dispatcher function for the specific parameter with rowref as parameter
   }
}
//************End of Parameter Despatch table ***********************

//Check paramter values going though each in the HTML table
function checkpars(){
  tab=document.getElementById("params")
  tab.caption.innerHTML="<span>Parameters</span>"
  trs=tab.rows
  if (document.getElementById("params").rows.length > 1)
    for(var i=1;i<trs.length;i++)  evalParam(trs[i].cells[0].innerText,trs[i]);  //Despatcher function takes name of parameter and row of HTML table as parameters
  else  strfind += "<li><b>Partial Data Collection</b></li>"
 }

//Cells with value greater than autovacuum_freeze_max_age
function aged(cell){
 if(cell.innerHTML > autovacuum_freeze_max_age){ cell.classList.add("warn"); cell.title =  Number(cell.innerText).toLocaleString("en-US"); }
}

//Check Table Level info
function checktabs(){
  const startTime =new Date().getTime();
  tab=document.getElementById("tabInfo")
  tab.caption.innerHTML="<span>Tables</span> in '" + obj.dbts.f1 + "' DB" 
  const trs=document.getElementById("tabInfo").rows
  const len=trs.length;
  setheadtip(trs[0],["Table Name and its OID","","Namespace / Schema OID","Bloat in Percentage","Live Rows/Tuples","Dead Rows/Tuples","Dead/Live ratio","Table (main fork) size in bytes",
  "Total Table size (All forks + TOAST) in bytes","Total Table size + Associated Indexes size in bytes","","","","Number of Vacuums per day","","Size of TOAST and its index",
   "Age of TOAST","Bigger of Table age and TOAST age","Number of Blocks Read/Fetched","Cache hit while reading","Time of last usage"]);
  [10,16,17].forEach(function(num){trs[0].cells[num].title="Age of unfrozen tuple. Indication of the need for VACUUM FREEZE. Current autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US")})
  for(var i=1;i<len;i++){
  //TODO : trs.forEach (convert the for loop to forEach if possible)
    tr=trs[i]; let TotTab=tr.cells[8]; TotTabSize=Number(TotTab.innerHTML); TabInd=tr.cells[9]; TabIndSize=(TabInd.innerHTML);
    if(TotTabSize > 5000000000 ) { TotTab.classList.add("lime"); TotTab.title = bytesToSize(TotTabSize) + "\nBig Table, Consider Partitioning, Archive+Purge"; 
    } else TotTab.title=bytesToSize(TotTabSize);
    //Tab above 20MB and with Index bigger than Tab
    if( TabIndSize > 2*TotTabSize && TotTabSize > 2000000 ){ TabInd.classList.add("warn"); TabInd.title="Indexes of : " + bytesToSize(TabIndSize-TotTabSize) + " is " + ((TabIndSize-TotTabSize)/TotTabSize).toFixed(2) + "x of Table " + bytesToSize(TotTabSize) + "\n Total : " + bytesToSize(TabIndSize)
    } else TabInd.title=bytesToSize(TabIndSize); 
    //Tab+Ind > 10GB
    if (TabIndSize > 10000000000) TabInd.classList.add("lime");
    //Check vacuum frequncy
    if (tr.cells[13].innerText / obj.dbts.f4 > 12){ tr.cells[13].classList.add("warn");  tr.cells[13].title="Too frequent vacuum runs : " + Math.round(tr.cells[13].innerText / obj.dbts.f4) + "/day"; }
    //Check the TOAST size
    if (tr.cells[15].innerText > 10000) { 
      tr.cells[15].title=bytesToSize(Number(tr.cells[15].innerText)); 
      //if TOAST is more than 10GB
      if (tr.cells[15].innerText > 10737418240) tr.cells[15].classList.add("warn")
      else tr.cells[15].classList.add("lime")
    }
    aged(tr.cells[10]);
    aged(tr.cells[16]);
    aged(tr.cells[17]);
    //Check reads per day
    if (tr.cells[18].innerText / obj.dbts.f4 > 262144 ){  //More than 2GB fetches per day. Specified in terms of blocks of 8196 bytes
      tr.cells[18].classList.add("lime"); 
      tr.cells[18].title="High Utilization : " + bytesToSize(Math.round(tr.cells[18].innerText * 8192 / obj.dbts.f4)) + "/day"; 
      //Inspect the cache hit ratio also if utilization is high.
      if(tr.cells[19].innerText < 40 ){ tr.cells[19].classList.add("warn"); tr.cells[19].title="Poor cache hit ratio, Results in high DiskReads"; }
      else if (tr.cells[19].innerText < 70) tr.cells[19].classList.add("lime");
     }
  }
const endTime = new Date().getTime();
console.log("time taken for checktabs :" + (endTime - startTime));
}

//Inspect database level info
function checkdbs(){
  //second column in the table is hidden, be careful
  const trs=document.getElementById("dbs").rows
  const len=trs.length;
  let aborts=[];  //array of dbnames where high aborts are happening
  let strtmp="";  //string to hold temp file generation info.
  trs[0].cells[6].title="Average Temp generation Per Day"; trs[0].cells[7].title="Average Temp generation Per Day"; trs[0].cells[9].title="autovacuum_freeze_max_age=" + autovacuum_freeze_max_age.toLocaleString("en-US");
  for(var i=1;i<len;i++){
    tr=trs[i];
    if(obj.dbts !== null && tr.cells[0].innerHTML == obj.dbts.f1) tr.cells[0].classList.add("lime");
    //High number of transaction aborts/rollbacks
    if(tr.cells[3].innerHTML > 4000){ tr.cells[3].classList.add("warn"); tr.cells[3].title = "High number of transaction aborts/rollbacks. Please inspect PostgreSQL logs"; 
     aborts.push(tr.cells[0].innerHTML)
     }
    [7,8].forEach(function(num) {  if (tr.cells[num].innerText > 1048576) { if(tr.cells[num].classList.length < 1) tr.cells[num].classList.add("lime"); tr.cells[num].title=bytesToSize(tr.cells[num].innerText) } });
    //More than 50GB temp generation per day. removing class even if it is not there is not causing any error
    if(tr.cells[7].innerHTML > 50000000000) {  
      tr.cells[7].classList.remove("lime"); tr.cells[7].classList.add("warn"); 
      let str = " temp file generation per day!. It can cause I/O performance issues." 
      let param = params.find(p => p.param === "log_temp_files");
      if ( param["val"] == -1 ) { 
        param["suggest"] = "'100MB'"; 
        str += "Consider setting log_temp_files=" + param["suggest"] + " to collect the problematic SQL statements to PostgreSQL logs";
      }else{
        str += "log_temp_files is already enabled, Analyze the PostgreSQL logs to check the problematic SQL statements";
      }
      evalParam("log_temp_files");
      if (strtmp != "") strtmp+= ","
      strtmp +=  tr.cells[7].title +"/day on "+tr.cells[0].innerHTML; 
      tr.cells[7].title += str;
    }
    totdb=totdb+Number(tr.cells[8].innerText);
    aged(tr.cells[9]);
  }
  if (aborts.length >0)  //Mention the aborts in findings.  future append aborts array to json  : obj.aborts=aborts;
   strfind += "<li>High number of transaction aborts/rollbacks in databases : <b>" + aborts.toString() + "</b>, please inspect PostgreSQL logs for more details</li>" ; 
  if (strtmp != "") strfind += "<li>High temp file generation : <b>" + strtmp + "</b></li>"; 
}

function checkextn(){
  const tab=document.getElementById("tblextn");
  tab.caption.innerHTML="<span>Extensions</span> in '" + obj.dbts.f1 + "' DB" 
  const trs=tab.rows
  const len=trs.length;
  let riskyExtn=[];
  if (len > 4) strfind += "<li><b>"+ (len-1).toString() +" Additional Extensions found.</b> Extensions can cause considerable overhead and performance degradataion. <a href='"+ docurl +"extensions.html'>Details</a></li>"
  for(var i=1;i<len;i++){
    tr=trs[i];
    //if the extension name is found in riskyExtn list, warn
    if (meta.riskyExtn.includes(tr.cells[1].innerHTML)){ tr.cells[1].classList.add("warn"); tr.cells[1].title = "Risky to use in mission critical systems without support aggrement. Crashes are reported" ; }
    //else if the extension name is not found in meta.commonExtn, highlight it.
    else if (!meta.commonExtn.includes(tr.cells[1].innerHTML)) tr.cells[1].classList.add("lime");
  }
}

function checkusers(){
  tab=document.getElementById("tblusr");
  tab.caption.innerHTML="<span>Users/Roles</span>  and connections"
  const trs=tab.rows
  let supr=0;
  for (var i=1;i<trs.length;i++){
    tr=trs[i];
    if(tr.cells[2].innerText == "t"){
      tr.cells[2].classList.add("lime");
      tr.cells[2].title =  "Super User"
      supr++;
    }
    if(tr.cells[5].innerText == "MD5"){
      tr.cells[5].classList.add("warn");
      tr.cells[5].title="Consider switching to SCRAM for better security whever possible"
    }
  }
  if (supr > 2 ) strfind += "<li>There are <b>" + supr + " Super user accounts</b>, consider this from the security standpoint</li>"
}

function checkhba(){
  tab=document.getElementById("tblhba");
  tab.caption.innerHTML="<span>HBA rules</span> analysis for security"
  const trs=tab.rows
  for (var i=1;i<trs.length;i++){
    tr=trs[i];
    if (!["::1","127.0.0.1","","samehost"].includes(tr.cells[4].innerText.trim()) && tr.cells[8].innerText.trim() != "reject" ){
      if(tr.cells[7].innerText == "IPv4"){
        if(tr.cells[5].innerText < 24){ 
          tr.cells[5].classList.add("warn");
          tr.cells[5].title="Avoid keeping the subnet mask wide open"
        } else if(tr.cells[5].innerText < 32) tr.cells[5].classList.add("lime")

        if(tr.cells[8].innerText == "md5"){
          tr.cells[8].classList.add("warn");
          tr.cells[8].title="Consider switching to SCRAM (scram-sha-256) for better security whever possible"
        }else if(tr.cells[8].innerText == "trust"){
          tr.cells[8].classList.add("warn");
          tr.cells[8].title="Avoid blindly trusting connection from outside"
        }
      }
      if(tr.cells[4].innerText == "all"){
          tr.cells[4].classList.add("warn");
          tr.cells[4].title="Avoid allowing connetions from all addresses"
      } else tr.cells[4].classList.add("lime")
    }
  }
}

//Sort logic
const getCellValue = (tr, idx) => tr.children[idx].innerText || tr.children[idx].textContent;
const comparer = (idx, asc) => (a, b) => ((v1, v2) =>   v1 !== ''' && v2 !== ''' && !isNaN(v1) && !isNaN(v2) ? v1 - v2 : v1.toString().localeCompare(v2))(getCellValue(asc ? a : b, idx), getCellValue(asc ? b : a, idx));
document.querySelectorAll(''th'').forEach(th => th.addEventListener(''click'', (() => {
  const table = th.closest(''table'');
  th.style.cursor = "progress";
  var el=document.createElement("div");
  el.setAttribute("id", "cur");
  if (this.asc) el.textContent = "⬆";
  else el.textContent = "⬇";
  th.appendChild(el);
  setTimeout(() => { el.remove();},1000);
  setTimeout(function (){
  Array.from(table.querySelectorAll(''tr:nth-child(n+2)'')).sort(comparer(Array.from(th.parentNode.children).indexOf(th), this.asc = !this.asc)).forEach(tr => table.appendChild(tr) );
  setTimeout(function(){th.style.cursor = "pointer";},10);
  },50);
})));

/////############## Pop-up details box######################
//Pop-up at DB info
function dbsdtls(th){
  let o=JSON.parse(th.cells[1].innerText);
  let str="";
  if(th.cells[0].classList.contains("lime")) str = "<br/>(pg_gather connected)";
  return "<b>" + th.cells[0].innerText + "</b>" + str + "<br/> Inserts per day : " + o.f1 + "<br/>Updates per day : " + o.f2 + "<br/>Deletes per day : " 
   + o.f3 + "<br/>Stats Reset : " + o.f4 + "<br/>DB oid(dbid) :" + o.f5 + "<br/>Multi Txn Id Age :" + o.f6  ;
}

//Pop-up for Tables.
function tabdtls(th){
  let o=JSON.parse(th.cells[1].innerText);
  let vac=th.cells[13].innerText;
  //lookup cells[2] value, the oid of NS in the obj.ns json collection  
  let ns=obj.ns.find(el => el.nsoid === JSON.parse(th.cells[2].innerText).toString());
  let str=""
  if (o.f11 == "r") str += "<br/>Inheritance Partition of : " + o.f10;
  if (o.f11 == "p") str += "<br/>Native Partition of : " + o.f10;
  if (o.f6 !== null) str += "<br/>Total Indexes: " + o.f6;
  if (o.f7 !== null) str += "<br/>Unused Indexes: " + o.f7;
  if (o.f8 > 0) str += "<br/>Primary key: Exists";
  else str += "<br/>No Primary key ";
  if (o.f9-o.f8 > 0) str += "<br/>Unique keys (than PK): " + (o.f9-o.f8);
  if (obj.dbts.f4 < 1) obj.dbts.f4 = 1;
  if (vac > 0) str +="<br />Vacuums / day : " + Number(vac/obj.dbts.f4).toFixed(1);
  str += "<br/>Inserts / day : " + Math.round(o.f2/obj.dbts.f4);
  str += "<br/>Updates / day : " + Math.round(o.f3/obj.dbts.f4);
  str += "<br/>Deletes / day : " + Math.round(o.f4/obj.dbts.f4);
  str += "<br/>HOT.updates / day : " + Math.round(o.f4/obj.dbts.f4);
  str += "<br>Rel.filename : " + o.f12;
  if (o.f13 < 16384) str += "<br>Tablespace : pg_default"; 
  else{
    let tbsp = obj.tbsp.find(el => el.tsoid === JSON.parse(o.f13).toString()); 
    str += "<br>Tablespace : " + o.f13 + " (" + tbsp.tsname + " : " + tbsp.location + ")"; 
  }
  if (o.f14 !== null ) str += "<br>Current Settings : " + o.f14;
  if(o.f3 > 0 || vac/obj.dbts.f4 > 50){
    str += "<br><b><u>RECOMMENDATIONS : </u></b>"
  if (o.f3 > 0) str += "<br/>FILLFACTOR :" + Math.round(100 - 20*o.f3/(o.f3+o.f2)+ 20*o.f3*o.f5/((o.f3+o.f2)*o.f3));
  if (vac/obj.dbts.f4 > 50) { 
    let threshold = Math.round((Math.round(o.f3/obj.dbts.f4) + Math.round(o.f4/obj.dbts.f4))/48);  //(UPDATEs per day + DELETEs per day) / 48
    if (threshold < 500) threshold = 500;
    str += "<br/>AUTOVACUUM : autovacuum_vacuum_threshold = "+ threshold +", autovacuum_analyze_threshold = " + threshold
  }}
  return "<b>" + th.cells[0].innerText + "</b><br/>OID : " + o.f1 + "</b><br/>Schema : " + ns.nsname + str;
}

//Pop-up for Session details
function sessdtls(th){
  let o=JSON.parse(th.cells[1].innerText); let str="";
  if (o.f1 !== null) str += "Database :" + o.f1 + "<br/>";
  if (o.f2 !== null && o.f2.length > 1 ) str += "Application :" + o.f2 + "<br/>";
  if (o.f3 !== null) str += "Client Host :" + o.f3 + "<br/>";
  if (o.f4 != null) str += "Communication :" + o.f4 + "<br/>";
  if (o.f5 != null) str += "Workers :" + o.f5 + "<br/>";
  //o.f6 is injected from checksess() into JSON. "f6" is hard coded.
  if (typeof o.f6 != "undefined") str += ''<div class="warn">'' + o.f6 + "<div>";
  if (str.length < 1) str+="Independent/Background process";
  return str;
}

function userdtls(tr){
if(tr.cells[1].innerText.length > 2){
  let o=JSON.parse(tr.cells[1].innerText); let str="<b><u>Connections per DB by user '"+tr.cells[0].innerText+"'</u></b><br>";
  for(i=0;i<o.length;i++){
    str += (i+1).toString() + ". Database:" + o[i].f1 + " Active:" + o[i].f2 + ", IdleInTrans:" + o[i].f3  + ", Idle:" + o[i].f4 +  " <br>";
  }
  return str
} else return "No connections"
}

function dbcons(tr){
if(tr.cells[1].innerText.length > 2){
  let o=JSON.parse(tr.cells[1].innerText); let str="<b><u>User connections to DB \'"+ tr.cells[0].innerText +"'</u></b><br>";
  for(i=0;i<o.length;i++){
    str += (i+1).toString() + ". User:" + o[i].f1 + " Active:" + o[i].f2 + ", IdleInTrans:" + o[i].f3  + ", Idle:" + o[i].f4 +  " <br>";
  }
  return str
} else return "No connections"
}

//Every HTML Table with hidden columns
document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseover", (() => {
  tr=td.parentNode;
  tab=tr.closest("table");
  var el=document.createElement("div");
  el.setAttribute("id", "dtls");
  el.setAttribute("align","left");
  if(tab.id=="dbs") el.innerHTML=dbsdtls(tr);
  if(tab.id=="tabInfo") el.innerHTML=tabdtls(tr);
  if(tab.id=="tblsess") el.innerHTML=sessdtls(tr);
  if(tab.id=="tblusr") el.innerHTML=userdtls(tr);
  if(tab.id=="tblcs") el.innerHTML=dbcons(tr);
  tr.cells[2].appendChild(el);
})));

document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("dblclick", (() => {
  navigator.clipboard.writeText(td.parentNode.cells[2].children[0].innerText);
  flash("Details copied to clipboard");
})));

//On mouseout, remove the div element. "fistchild" don't have the div element
document.querySelectorAll(".thidden tr td:first-child").forEach(td => td.addEventListener("mouseout", (() => {
  td.parentNode.cells[2].innerHTML=td.parentNode.cells[2].firstChild.textContent;
})));

//special pop-up for sections menu
let elem=document.getElementById("bottommenu")
elem.onmouseover = function() { document.getElementById("menu").style.display = "block"; }
elem.onclick = function() { document.getElementById("menu").style.display = "none"; }
elem.onmouseout = function() { document.getElementById("menu").style.display = "none"; }
//################End of popup box##########################

//############## Copy SQL text to clibboard on double click ########################
document.querySelectorAll("#tblsess tr td:nth-child(6) , #tblstmnt tr td:nth-child(2)").forEach(td => td.addEventListener("dblclick", (() => {
  if (td.title){
  navigator.clipboard.writeText(td.title).then(() => {  
    // var el=document.createElement("div");
    // el.setAttribute("id", "cur");
    // el.textContent = "SQL text is copied to clipboard";
    // td.appendChild(el);
    // setTimeout(() => { el.remove();},2000);
    flash("SQL text is copied to clipboard");
   });
}
})));

//################ End of Expand box for query string ###############

//Index analysis
function checkindex(){
tab=document.getElementById("IndInfo")
tab.caption.innerHTML="<span>Indexes</span> in '" + obj.dbts.f1 + "' DB" 
trs=tab.rows;
for (let tr of trs) {
  if(tr.cells[4].innerText == 0) {tr.cells[4].classList.add("warn"); tr.cells[4].title="Unused Index"}
  tr.cells[5].title=bytesToSize(Number(tr.cells[5].innerText));
  if(tr.cells[5].innerText > 2000000000) tr.cells[5].classList.add("lime");
  if(tr.cells[6].innerText > 262144 && tr.cells[6].innerText/tr.cells[4].innerText > 50 ) {
    if (tr.cells[4].innerText > 0 ){
     tr.cells[6].title="Each Index scan had to fetch " + Math.round(tr.cells[6].innerText/tr.cells[4].innerText) + " pages on average. Expensive Index";
    }else tr.cells[6].title="Unused indexes. But causing fetches without any benefit"; 
    //(" + bytesToSize(Math.round(tr.cells[6].innerText*8192 / obj.dbts.f4)) + "/day)
    tr.cells[6].classList.add("warn");
    if (tr.cells[7].innerText < 50 ){tr.cells[7].classList.add("warn");tr.cells[7].title="Poor Cache Hit";}
    else if (tr.cells[7].innerText < 80 ) {tr.cells[7].classList.add("lime");tr.cells[7].title="Indexes with less cache hit can cause considerable I/O"; }
  }
}
}

//database time draw graph
function checkdbtime(){
tab=document.getElementById("tableConten")
tab.caption.innerHTML="<span>DB Server Time</span> - Wait-events, CPU time and Delays (<a href="+docurl+"waitevents.html>Reference</a>)"
trs=tab.rows;
let tempstr=""
if (trs.length > 1){ 
  maxevnt=Number(trs[1].cells[1].innerText);
  for (let tr of trs) {
   evnts=tr.cells[1];
   if (evnts.innerText*1500/maxevnt > 1) evnts.innerHTML += ''<div style="display:inline-block;width:'+ Number(evnts.innerText)*1500/maxevnt + 'px; border: 7px outset brown; border-width:7px 0; margin:0 5px;box-shadow: 2px 2px grey;">'';
   if (tr.cells[0].innerText == "CPU" && tr.cells[1].innerText > 100)   tempstr = "CPU usage is equivalent to " + (evnts.innerText*1.2/2000).toFixed(1) + " CPU cores (approx). "
  }
  //Add footer to table with available info.
  el=document.createElement("tfoot");
  el.innerHTML = "<th colspan='2'>"+ tempstr +" </th>";
  tab.appendChild(el);
}else {
  tab.tBodies[0].innerHTML="No Wait Event information or CPU usage information is available, Probably the PostgreSQL is completely idle or data collection failed"
}
}

//Session information.
function checksess(){
tab=document.getElementById("tblsess")
tab.caption.innerHTML=''<span>Sessions</span>''
trs=tab.rows;
for (let tr of trs){
 //column references
 pid=tr.cells[0]; sql=tr.cells[5]; xidage=tr.cells[8]; stime=tr.cells[10];
 if(xidage.innerText > 20) xidage.classList.add("warn");
 //if pid exists in blockers list and victims list
 if (blokers.indexOf(Number(pid.innerText)) > -1){ pid.classList.add("high"); pid.title="Blocker"; 
   tr.cells[1].innerText = updateJson( tr.cells[1].innerText , "f6", "Blocker")
 };
 if (blkvictims.indexOf(Number(pid.innerText)) > -1) { 
   pid.classList.add("warn"); 
   tr.cells[1].innerText = updateJson( tr.cells[1].innerText , "f6", "Victim of Blocker: " + obj.victims.find(el => el.f1 == pid.innerText).f2.toString())
  };
  if(DurationtoSeconds(stime.innerText) > 300 && tr.cells[7].innerText.length > 3) stime.classList.add("warn");
 //if query text is more than 100 chars, copy that to title and trim the query string to 100
 if (sql.innerText.length > 100 && !sql.innerText.startsWith("**") ){ 
  sql.title = sql.innerText; 
  sql.innerText = sql.innerText.substring(0, 100); 
 };
}}

function checkstmnts(){
//if there is no info from pg_stat_statements
let tab= document.getElementById("tblstmnt");
tab.caption.innerHTML = "<span>Top Statements</span>"
if(tab.rows.length < 2) 
 tab.tBodies[0].innerHTML="No pg_stat_statements or pg_stat_monitor info found" //if there is nothing in the table, remove the table
else{
 trs=tab.rows;
 setTitles(trs[0],["Weighted Dense Ranking. 1 has the highest impact","SQL Statement","SQL workload / Total workload %","Number of execution of the statement",
 "Avg. execution time of the statement (ms)","Average Reads (Blocks)","Cache Hit %","Avg. Dirtied Pages","Avg. Written Pages","Avg. Temp Read","Avg. Temp Write"]);
  for (let tr of trs){
 sql=tr.cells[1];
 if (sql.innerText.length > 10 ){ sql.title = sql.innerText; sql.innerText = sql.innerText.substring(0, 100); }
 let cel=tr.cells[6]; //Cache hit column. If cache it is poor highlight accordingly
 if ( cel.innerText.trim() != "" && cel.innerText < 50) cel.classList.add("warn"); // else if (cel.innerText < 90) cel.classList.add("lime");
 cel=tr.cells[9]; //Temp Read. if average temp read is more than 100MB highlight
 if (cel.innerText > 12800) cel.classList.add("lime");
 cel=tr.cells[10]; //Temp Write. If aveage temp write is more than 100MB highlight
 if (cel.innerText > 12800) cel.classList.add("lime");
}}}

function setTitles(tr,tiltes){
  for(i=0;i<tiltes.length;i++) tr.cells[i].title=tiltes[i];
}

//Checkpointer and bgwriter info
function checkchkpntbgwrtr(){
tab=document.getElementById("tblchkpnt")
tab.caption.innerHTML=''<span>BGWriter & Checkpointer</span>''
trs=tab.rows;
setTitles(trs[0],["Forced Checkpoint; Checkpoint triggered by xlog/wal; Need to adjust the max_wal_size","Average Minutes between Checkpoints","Average Write time of a checkpoint",
"Average Disk sync time of a checkpoint","","","","","","","","Dirty buffers cleaned by Checkpointer","Dirty buffers cleaned by BGWriter","Dirty buffers cleaned by Session backends",
"Percentage of bgwriter runs results in a halt","Percentage of bgwriter halts are due to hitting on bgwriter_lru_maxpages limit","Number of days before stats have been reset"]);
if (trs.length > 1){
  tr=trs[1]
  if (tr.cells[0].innerText > 10){
    tr.cells[0].classList.add("high"); tr.cells[0].title="More than 10% of forced checkpoints is not desirable, increase max_wal_size";
  }
  if(tr.cells[1].innerText < 10 ){
    tr.cells[1].classList.add("high"); tr.cells[1].title="checkpoints are too frequent. consider checkpoint_timeout=1800";
  }
  if(tr.cells[11].innerText > 50){
    tr.cells[11].classList.add("high"); tr.cells[11].title="Checkpointer is taking high load of cleaning dirty buffers";
  }
  if(tr.cells[13].innerText > tr.cells[12].innerText){   //if Backends cleans more pages than BgWriter, we have a problem to address
    tr.cells[12].classList.add("high"); tr.cells[12].title="Bgwriter should be cleaning more pages than backends.";
    if (tr.cells[13].innerText > 30){ tr.cells[13].classList.add("high"); tr.cells[13].title="too many dirty pages cleaned by backends"; 
    strfind += "<li>High <b>memory pressure</b>. Consider increasing RAM and shared_buffers</li>"; }   //add to findings
    if(tr.cells[12].innerText < 20){  //if BgWriter cleans less than 20% dirty pages, we should consider to make it more aggressive.
      tr.cells[12].classList.add("high"); tr.cells[12].title+="Bgwriter is not efficient";
      if(tr.cells[14].innerText > 30){
        tr.cells[14].classList.add("high"); tr.cells[14].title="bgwriter could run more frequently. reduce bgwriter_delay";
      }
      if(tr.cells[15].innerText > 10){
        let param = params.find(p => p.param === "bgwriter_lru_maxpages");
        param["suggest"] = Math.ceil((parseInt(param["val"]) + tr.cells[15].innerText/15*100)/100)*100; //calculate new parameter value and suggest
        evalParam("bgwriter_lru_maxpages");
        tr.cells[15].classList.add("high"); tr.cells[15].title="bgwriter halts too frequently. increase bgwriter_lru_maxpages";
      }
    }
  }
  if (tr.cells[16].innerText.trim() == "" || tr.cells[16].innerText < 1 ){ //if "Reset days" is empty or less than a day
    tr.cells[16].classList.add("high"); tr.cells[16].title="sufficient bgwriter stats are not available";
    document.getElementById("tblchkpnt").classList.add("high");
    document.getElementById("tblchkpnt").title = "Sufficient bgwriter stats are not available. This could happen if data is collected immediately after the stats reset or a crash. At least one day of stats are required to do meaningful calculations";
  }
  if( tr.cells[16].innerText > 45 ){ //if "Reset days" is more than 45 days.
    tr.cells[16].classList.add("high"); tr.cells[16].title="Statistics of long-term avarage won't be helpful. Please consider resetting. 1 week is ideal";
  }
}}

function checkiostat(){
tab=document.getElementById("tbliostat")
tab.caption.innerHTML=''<span>IO Statistics</span>''
if (tab.rows.length > 1){
}else  tab.tBodies[0].innerHTML="IO statistics is available for PostgreSQL 16 and above"
}


//Check Replication status
tab=document.getElementById("tblreplstat")
tab.caption.innerHTML="<span>Replication</span>"
if (tab.rows.length > 1){
  for(var i=1;i<tab.rows.length;i++){
    row=tab.rows[i];
    [4,5,6,7,16,17].forEach(function(num){ cell=row.cells[num]; cell.title=bytesToSize(Number(cell.innerText),1024); 
     if(cell.innerText > 104857600){
      cell.classList.add("warn");
     }else{
      cell.classList.add("lime");
     }
    });
    //xmin age check
    [14,15].forEach(function(num){  if(row.cells[num].innerText > 20) row.cells[num].classList.add("warn"); });
    //check for abandoned replication slots
    if (row.cells[13].innerText == "f" || row.cells[2].innerText == "") {
      row.cells[8].classList.add("high");
      row.cells[8].title="Abandoned replication slot";
      document.getElementById("finditem").innerHTML += "<li> Abandoned replication slot : <b>" +  row.cells[8].innerText + "</b> found. This can cause unwanted WAL retention" ;
    }
  }
}else{
  tab.tBodies[0].innerHTML="No Replication data found"
}


//Press Alt_i to go to topics
document.onkeyup = function(e) {
  if (e.altKey && e.which === 73) document.getElementById("topics").scrollIntoView({behavior: "smooth"});
  //       e.preventDefault();
}
</script>
</html>
